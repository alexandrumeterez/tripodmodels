{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tripod-ml in /home/alex/.local/lib/python3.7/site-packages (0.1.0.4)\n",
      "Requirement already satisfied: requests in /usr/lib/python3.7/site-packages (from tripod-ml) (2.22.0)\n",
      "Requirement already satisfied: tqdm in /home/alex/.local/lib/python3.7/site-packages (from tripod-ml) (4.36.1)\n",
      "Requirement already satisfied: joblib in /home/alex/.local/lib/python3.7/site-packages (from tripod-ml) (0.14.0)\n",
      "Requirement already satisfied: bpe in /home/alex/.local/lib/python3.7/site-packages (from tripod-ml) (1.0)\n",
      "Requirement already satisfied: torch in /home/alex/.local/lib/python3.7/site-packages (from tripod-ml) (1.2.0)\n",
      "Requirement already satisfied: sklearn in /home/alex/.local/lib/python3.7/site-packages (from tripod-ml) (0.0)\n",
      "Requirement already satisfied: numpy in /home/alex/.local/lib/python3.7/site-packages (from tripod-ml) (1.16.4)\n",
      "Requirement already satisfied: chardet>=3.0.2 in /usr/lib/python3.7/site-packages (from requests->tripod-ml) (3.0.4)\n",
      "Requirement already satisfied: idna>=2.5 in /usr/lib/python3.7/site-packages (from requests->tripod-ml) (2.8)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in /usr/lib/python3.7/site-packages (from requests->tripod-ml) (1.25.5)\n",
      "Requirement already satisfied: hypothesis in /home/alex/.local/lib/python3.7/site-packages (from bpe->tripod-ml) (4.42.10)\n",
      "Requirement already satisfied: nltk in /home/alex/.local/lib/python3.7/site-packages (from bpe->tripod-ml) (3.4.5)\n",
      "Requirement already satisfied: toolz in /home/alex/.local/lib/python3.7/site-packages (from bpe->tripod-ml) (0.10.0)\n",
      "Requirement already satisfied: pytest in /home/alex/.local/lib/python3.7/site-packages (from bpe->tripod-ml) (5.2.2)\n",
      "Requirement already satisfied: mypy in /home/alex/.local/lib/python3.7/site-packages (from bpe->tripod-ml) (0.740)\n",
      "Requirement already satisfied: scikit-learn in /home/alex/.local/lib/python3.7/site-packages (from sklearn->tripod-ml) (0.21.3)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /usr/lib/python3.7/site-packages (from hypothesis->bpe->tripod-ml) (19.2.0)\n",
      "Requirement already satisfied: six in /usr/lib/python3.7/site-packages (from nltk->bpe->tripod-ml) (1.12.0)\n",
      "Requirement already satisfied: pluggy<1.0,>=0.12 in /home/alex/.local/lib/python3.7/site-packages (from pytest->bpe->tripod-ml) (0.13.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in /home/alex/.local/lib/python3.7/site-packages (from pytest->bpe->tripod-ml) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/lib/python3.7/site-packages (from pytest->bpe->tripod-ml) (0.23)\n",
      "Requirement already satisfied: wcwidth in /usr/lib/python3.7/site-packages (from pytest->bpe->tripod-ml) (0.1.7)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /usr/lib/python3.7/site-packages (from pytest->bpe->tripod-ml) (4.3.0)\n",
      "Requirement already satisfied: packaging in /usr/lib/python3.7/site-packages (from pytest->bpe->tripod-ml) (19.2)\n",
      "Requirement already satisfied: py>=1.5.0 in /home/alex/.local/lib/python3.7/site-packages (from pytest->bpe->tripod-ml) (1.8.0)\n",
      "Requirement already satisfied: typed-ast<1.5.0,>=1.4.0 in /home/alex/.local/lib/python3.7/site-packages (from mypy->bpe->tripod-ml) (1.4.0)\n",
      "Requirement already satisfied: mypy-extensions<0.5.0,>=0.4.0 in /home/alex/.local/lib/python3.7/site-packages (from mypy->bpe->tripod-ml) (0.4.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /home/alex/.local/lib/python3.7/site-packages (from mypy->bpe->tripod-ml) (3.7.4.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /home/alex/.local/lib/python3.7/site-packages (from scikit-learn->sklearn->tripod-ml) (1.3.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/lib/python3.7/site-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest->bpe->tripod-ml) (0.6.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/lib/python3.7/site-packages (from packaging->pytest->bpe->tripod-ml) (2.4.2)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchtext.data import Field\n",
    "from torchtext.data import TabularDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "!pip3 install tripod-ml --user\n",
    "from tripod.api import Tripod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "#Change here\n",
    "DATASET='snli'\n",
    "\n",
    "tripod=Tripod()\n",
    "tripod.load('wiki-103')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelA(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(900 * 2, 600)\n",
    "        self.fc2 = nn.Linear(600, 300)\n",
    "        self.fc3 = nn.Linear(300, 100)\n",
    "        self.fc4 = nn.Linear(100, 50)\n",
    "        self.fc5 = nn.Linear(50, 3)\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.fc4(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc5(x)\n",
    "        return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelB(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_out):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_out)\n",
    "        self.gru_A = nn.GRU(input_size=emb_out, hidden_size=200, num_layers=1, bidirectional=True)\n",
    "        self.gru_B = nn.GRU(input_size=emb_out, hidden_size=200, num_layers=1, bidirectional=True)\n",
    "        self.fc = nn.Linear(800, 3)\n",
    "    def forward(self, sentA, sentB):\n",
    "        embedded_A = self.embedding(sentA)\n",
    "        embedded_B = self.embedding(sentB)\n",
    "        print(embedded_A.shape)\n",
    "        output_A, hidden_A = self.gru_A(embedded_A)\n",
    "        output_B, hidden_B = self.gru_B(embedded_B)\n",
    "        hidden_A_concat = torch.cat((hidden_A[-2,:,:], hidden_A[-1,:,:]), dim=1)\n",
    "        hidden_B_concat = torch.cat((hidden_B[-2,:,:], hidden_B[-1,:,:]), dim=1)\n",
    "        hidden = torch.cat((hidden_A_concat, hidden_B_concat), dim=1)\n",
    "\n",
    "        out = self.fc(hidden)\n",
    "        return F.softmax(out, dim=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelC(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_out):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_out)\n",
    "        self.gru_A = nn.GRU(input_size=emb_out, hidden_size=200, num_layers=1, bidirectional=True)\n",
    "        self.gru_B = nn.GRU(input_size=emb_out, hidden_size=200, num_layers=1, bidirectional=True)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(900 * 2, 600),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(600, 300),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(300, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 50),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc1 = nn.Linear(850, 3)\n",
    "    def forward(self, sentAtokens, sentBtokens, concatTripod):\n",
    "        embedded_A = self.embedding(sentAtokens)\n",
    "        embedded_B = self.embedding(sentBtokens)\n",
    "        output_A, hidden_A = self.gru_A(embedded_A)\n",
    "        output_B, hidden_B = self.gru_B(embedded_B)\n",
    "        hidden_A_concat = torch.cat((hidden_A[-2,:,:], hidden_A[-1,:,:]), dim=1)\n",
    "        hidden_B_concat = torch.cat((hidden_B[-2,:,:], hidden_B[-1,:,:]), dim=1)\n",
    "        hidden = torch.cat((hidden_A_concat, hidden_B_concat), dim=1)\n",
    "        \n",
    "        tripod_out = self.fc(concatTripod)\n",
    "        \n",
    "        print(hidden.shape)\n",
    "        print(tripod_out.shape)\n",
    "        \n",
    "        out = torch.cat((hidden, tripod_out), dim=1)\n",
    "        out = self.fc1(out)\n",
    "        return F.softmax(out, dim=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelD(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_out):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_out)\n",
    "        self.gru_A = nn.GRU(input_size=emb_out + 900, hidden_size=200, num_layers=1, bidirectional=True)\n",
    "        self.gru_B = nn.GRU(input_size=emb_out + 900, hidden_size=200, num_layers=1, bidirectional=True)\n",
    "        self.fc = nn.Linear(800, 3)\n",
    "    def forward(self, sentA, sentB, sentAtripod, sentBtripod):\n",
    "        embedded_A = self.embedding(sentA)\n",
    "        embedded_B = self.embedding(sentB)\n",
    "        \n",
    "        embedded_A = torch.cat((embedded_A, sentAtripod.repeat(embedded_A.shape[0], 1).view(embedded_A.shape[0], -1, 900)), dim=2)\n",
    "        embedded_B = torch.cat((embedded_B, sentBtripod.repeat(embedded_B.shape[0], 1).view(embedded_B.shape[0], -1, 900)), dim=2)\n",
    "\n",
    "        \n",
    "        output_A, hidden_A = self.gru_A(embedded_A)\n",
    "        output_B, hidden_B = self.gru_B(embedded_B)\n",
    "        hidden_A_concat = torch.cat((hidden_A[-2,:,:], hidden_A[-1,:,:]), dim=1)\n",
    "        hidden_B_concat = torch.cat((hidden_B[-2,:,:], hidden_B[-1,:,:]), dim=1)\n",
    "        hidden = torch.cat((hidden_A_concat, hidden_B_concat), dim=1)\n",
    "\n",
    "        out = self.fc(hidden)\n",
    "        return F.softmax(out, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET == 'sick':\n",
    "    TRAIN_PATH = './sick_train/SICK_train.txt'\n",
    "    TEST_PATH = './sick_test/SICK_test.txt'\n",
    "if DATASET == 'snli':\n",
    "    TRAIN_PATH = './snli_1.0/snli_1.0/snli_1.0_train.txt'\n",
    "    TEST_PATH = './snli_1.0/snli_1.0/snli_1.0_test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_FIELD = Field(sequential=True, tokenize=lambda x: x.split(), lower=True)  # tokenizer is identity since we already tokenized it to compute external features\n",
    "LABEL = Field(sequential=False, use_vocab=False, lower=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET == 'sick':\n",
    "    datafields = [(\"pair_ID\", None),\n",
    "                  (\"sentence_A\", TEXT_FIELD),\n",
    "                  (\"sentence_B\", TEXT_FIELD),\n",
    "                  (\"relatedness_score\", None),\n",
    "                  (\"entailment_judgment\", LABEL)]\n",
    "if DATASET == 'snli':\n",
    "    datafields = [(\"entailment_judgment\", LABEL),\n",
    "                 (\"sentence1_binary_parse\", None),\n",
    "                 (\"sentence2_binary_parse\", None),\n",
    "                 (\"sentence1_parse\", None),\n",
    "                 (\"sentence2_parse\", None),\n",
    "                 (\"sentence_A\", TEXT_FIELD),\n",
    "                 (\"sentence_B\", TEXT_FIELD),\n",
    "                 (\"captionID\", None),\n",
    "                 (\"pairID\", None),\n",
    "                 (\"label1\", None),\n",
    "                 (\"label2\", None),\n",
    "                 (\"label3\", None),\n",
    "                 (\"label4\", None),\n",
    "                 (\"label5\", None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = TabularDataset.splits(path='./data', train=TRAIN_PATH, test=TEST_PATH, skip_header=True, format='TSV', fields=datafields) \n",
    "TEXT_FIELD.build_vocab(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = {'contradiction': 0, 'neutral': 1, 'entailment': 2}\n",
    "def generate_batch_A(batch):\n",
    "    label = torch.LongTensor([LABELS[entry.entailment_judgment] for entry in batch])\n",
    "    sentence_A = [' '.join(entry.sentence_A) for entry in batch]\n",
    "    sentence_B = [' '.join(entry.sentence_B) for entry in batch]\n",
    "    return sentence_A, sentence_B, label\n",
    "\n",
    "def generate_batch_B(batch):\n",
    "    def tokens_to_tensor(tokens):\n",
    "        return torch.LongTensor([TEXT_FIELD.vocab.stoi[t] for t in tokens])\n",
    "    \n",
    "    label = torch.LongTensor([LABELS[entry.entailment_judgment] for entry in batch])\n",
    "    sentence_A = [tokens_to_tensor(entry.sentence_A) for entry in batch]\n",
    "    sentence_B = [tokens_to_tensor(entry.sentence_B) for entry in batch]\n",
    "    return sentence_A, sentence_B, label\n",
    "\n",
    "def generate_batch_C_D(batch):\n",
    "    def tokens_to_tensor(tokens):\n",
    "        return torch.LongTensor([TEXT_FIELD.vocab.stoi[t] for t in tokens])\n",
    "    label = torch.LongTensor([LABELS.get(entry.entailment_judgment, 0) for entry in batch])\n",
    "    full_sentence_A = [' '.join(entry.sentence_A) for entry in batch]\n",
    "    full_sentence_B = [' '.join(entry.sentence_B) for entry in batch]\n",
    "    sentence_A = [tokens_to_tensor(entry.sentence_A) for entry in batch]\n",
    "    sentence_B = [tokens_to_tensor(entry.sentence_B) for entry in batch]\n",
    "    return (sentence_A, full_sentence_A), (sentence_B, full_sentence_B), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "def train_func(dataset, model_name, model, optimizer, criterion):\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    if model_name == 'A':\n",
    "        data = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=generate_batch_A)\n",
    "    if model_name == 'B':\n",
    "        data = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=generate_batch_B)\n",
    "    if model_name == 'C' or model_name == 'D':\n",
    "        data = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=generate_batch_C_D)\n",
    "    for idx, (sentsA, sentsB, labels) in enumerate(data):\n",
    "        optimizer.zero_grad()\n",
    "        if model_name == 'A':\n",
    "            tripod_sentsA = torch.tensor(tripod(sentsA))\n",
    "            tripod_sentsB = torch.tensor(tripod(sentsB))\n",
    "            model_input = torch.cat((tripod_sentsA, tripod_sentsB), dim=1)\n",
    "            output = model(model_input)\n",
    "        if model_name == 'B':\n",
    "            sentsA = nn.utils.rnn.pad_sequence(sentsA, padding_value=TEXT_FIELD.vocab.stoi['<pad>'])\n",
    "            sentsB = nn.utils.rnn.pad_sequence(sentsB, padding_value=TEXT_FIELD.vocab.stoi['<pad>'])\n",
    "            output = model(sentsA, sentsB)\n",
    "        if model_name == 'C':\n",
    "            sentsA, fullSentsA = sentsA[0], sentsA[1]\n",
    "            sentsB, fullSentsB = sentsB[0], sentsB[1]\n",
    "            \n",
    "            sentsA = nn.utils.rnn.pad_sequence(sentsA, padding_value=TEXT_FIELD.vocab.stoi['<pad>'])\n",
    "            sentsB = nn.utils.rnn.pad_sequence(sentsB, padding_value=TEXT_FIELD.vocab.stoi['<pad>'])\n",
    "            \n",
    "            tripod_sentsA = torch.tensor(tripod(fullSentsA))\n",
    "            tripod_sentsB = torch.tensor(tripod(fullSentsB))\n",
    "            tripod_concat = torch.cat((tripod_sentsA, tripod_sentsB), dim=1)\n",
    "            \n",
    "            \n",
    "            output = model(sentsA, sentsB, tripod_concat)\n",
    "        if model_name == 'D':\n",
    "            sentsA, fullSentsA = sentsA[0], sentsA[1]\n",
    "            sentsB, fullSentsB = sentsB[0], sentsB[1]\n",
    "            sentsA = nn.utils.rnn.pad_sequence(sentsA, padding_value=TEXT_FIELD.vocab.stoi['<pad>'])\n",
    "            sentsB = nn.utils.rnn.pad_sequence(sentsB, padding_value=TEXT_FIELD.vocab.stoi['<pad>'])\n",
    "            \n",
    "            tripod_sentsA = torch.tensor(tripod(fullSentsA))\n",
    "            tripod_sentsB = torch.tensor(tripod(fullSentsB))\n",
    "            \n",
    "            output = model(sentsA, sentsB, tripod_sentsA, tripod_sentsB)\n",
    "        loss = criterion(output, labels)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_acc += (output.argmax(1) == labels).sum().item()\n",
    "    return train_loss / len(data), train_acc / len(data)\n",
    "\n",
    "def test_func(dataset, model_name, model, criterion):\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    if model_name == 'A':\n",
    "        data = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=generate_batch_A)\n",
    "    if model_name == 'B':\n",
    "        data = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=generate_batch_B)\n",
    "    if model_name == 'C' or model_name == 'D':\n",
    "        data = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=generate_batch_C_D)\n",
    "    with torch.no_grad():\n",
    "        for idx, (sentsA, sentsB, labels) in enumerate(data):\n",
    "            if model_name == 'A':\n",
    "                tripod_sentsA = torch.tensor(tripod(sentsA))\n",
    "                tripod_sentsB = torch.tensor(tripod(sentsB))\n",
    "                model_input = torch.cat((tripod_sentsA, tripod_sentsB), dim=1)\n",
    "                output = model(model_input)\n",
    "            if model_name == 'B':\n",
    "                sentsA = nn.utils.rnn.pad_sequence(sentsA, padding_value=TEXT_FIELD.vocab.stoi['<pad>'])\n",
    "                sentsB = nn.utils.rnn.pad_sequence(sentsB, padding_value=TEXT_FIELD.vocab.stoi['<pad>'])\n",
    "                output = model(sentsA, sentsB)\n",
    "            if model_name == 'C':\n",
    "                sentsA, fullSentsA = sentsA[0], sentsA[1]\n",
    "                sentsB, fullSentsB = sentsB[0], sentsB[1]\n",
    "\n",
    "                sentsA = nn.utils.rnn.pad_sequence(sentsA, padding_value=TEXT_FIELD.vocab.stoi['<pad>'])\n",
    "                sentsB = nn.utils.rnn.pad_sequence(sentsB, padding_value=TEXT_FIELD.vocab.stoi['<pad>'])\n",
    "\n",
    "                tripod_sentsA = torch.tensor(tripod(fullSentsA))\n",
    "                tripod_sentsB = torch.tensor(tripod(fullSentsB))\n",
    "                tripod_concat = torch.cat((tripod_sentsA, tripod_sentsB), dim=1)\n",
    "                \n",
    "                output = model(sentsA, sentsB, tripod_concat)\n",
    "            if model_name == 'D':\n",
    "                sentsA, fullSentsA = sentsA[0], sentsA[1]\n",
    "                sentsB, fullSentsB = sentsB[0], sentsB[1]\n",
    "                sentsA = nn.utils.rnn.pad_sequence(sentsA, padding_value=TEXT_FIELD.vocab.stoi['<pad>'])\n",
    "                sentsB = nn.utils.rnn.pad_sequence(sentsB, padding_value=TEXT_FIELD.vocab.stoi['<pad>'])\n",
    "\n",
    "                tripod_sentsA = torch.tensor(tripod(fullSentsA))\n",
    "                tripod_sentsB = torch.tensor(tripod(fullSentsB))\n",
    "\n",
    "                output = model(sentsA, sentsB, tripod_sentsA, tripod_sentsB)\n",
    "\n",
    "            loss = criterion(output, labels)\n",
    "            test_loss += loss.item()\n",
    "            test_acc += (output.argmax(1) == labels).sum().item()\n",
    "    return test_loss / len(data), test_acc / len(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "N_EPOCHS = 5\n",
    "min_valid_loss = float('inf')\n",
    "\n",
    "MODEL_NAME = 'D'\n",
    "model = ModelD(len(TEXT_FIELD.vocab.stoi), 256)\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=TEXT_FIELD.vocab.stoi['<pad>']).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=4.0)\n",
    "\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    train_loss, train_acc = train_func(train, MODEL_NAME, model, optimizer, criterion)\n",
    "    valid_loss, valid_acc = test_func(test, MODEL_NAME, model, criterion)\n",
    "\n",
    "    secs = int(time.time() - start_time)\n",
    "    mins = secs / 60\n",
    "    secs = secs % 60\n",
    "\n",
    "    print('Epoch: %d' %(epoch + 1), \" | time in %d minutes, %d seconds\" %(mins, secs))\n",
    "    print(f'\\tLoss: {train_loss:.4f}(train)\\t|\\tAcc: {train_acc * 100:.1f}%(train)')\n",
    "    print(f'\\tLoss: {valid_loss:.4f}(valid)\\t|\\tAcc: {valid_acc * 100:.1f}%(valid)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
