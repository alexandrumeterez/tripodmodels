{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tripod-ml in /home/alex/.local/lib/python3.7/site-packages (0.1.0.4)\n",
      "Requirement already satisfied: sklearn in /home/alex/.local/lib/python3.7/site-packages (from tripod-ml) (0.0)\n",
      "Requirement already satisfied: joblib in /home/alex/.local/lib/python3.7/site-packages (from tripod-ml) (0.14.0)\n",
      "Requirement already satisfied: numpy in /home/alex/.local/lib/python3.7/site-packages (from tripod-ml) (1.16.4)\n",
      "Requirement already satisfied: tqdm in /home/alex/.local/lib/python3.7/site-packages (from tripod-ml) (4.36.1)\n",
      "Requirement already satisfied: bpe in /home/alex/.local/lib/python3.7/site-packages (from tripod-ml) (1.0)\n",
      "Requirement already satisfied: requests in /usr/lib/python3.7/site-packages (from tripod-ml) (2.22.0)\n",
      "Requirement already satisfied: torch in /home/alex/.local/lib/python3.7/site-packages (from tripod-ml) (1.2.0)\n",
      "Requirement already satisfied: scikit-learn in /home/alex/.local/lib/python3.7/site-packages (from sklearn->tripod-ml) (0.21.3)\n",
      "Requirement already satisfied: pytest in /home/alex/.local/lib/python3.7/site-packages (from bpe->tripod-ml) (5.2.2)\n",
      "Requirement already satisfied: hypothesis in /home/alex/.local/lib/python3.7/site-packages (from bpe->tripod-ml) (4.42.10)\n",
      "Requirement already satisfied: toolz in /home/alex/.local/lib/python3.7/site-packages (from bpe->tripod-ml) (0.10.0)\n",
      "Requirement already satisfied: mypy in /home/alex/.local/lib/python3.7/site-packages (from bpe->tripod-ml) (0.740)\n",
      "Requirement already satisfied: nltk in /home/alex/.local/lib/python3.7/site-packages (from bpe->tripod-ml) (3.4.5)\n",
      "Requirement already satisfied: chardet>=3.0.2 in /usr/lib/python3.7/site-packages (from requests->tripod-ml) (3.0.4)\n",
      "Requirement already satisfied: idna>=2.5 in /usr/lib/python3.7/site-packages (from requests->tripod-ml) (2.8)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in /usr/lib/python3.7/site-packages (from requests->tripod-ml) (1.25.5)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /home/alex/.local/lib/python3.7/site-packages (from scikit-learn->sklearn->tripod-ml) (1.3.1)\n",
      "Requirement already satisfied: packaging in /usr/lib/python3.7/site-packages (from pytest->bpe->tripod-ml) (19.2)\n",
      "Requirement already satisfied: wcwidth in /usr/lib/python3.7/site-packages (from pytest->bpe->tripod-ml) (0.1.7)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/lib/python3.7/site-packages (from pytest->bpe->tripod-ml) (19.2.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in /home/alex/.local/lib/python3.7/site-packages (from pytest->bpe->tripod-ml) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/lib/python3.7/site-packages (from pytest->bpe->tripod-ml) (0.23)\n",
      "Requirement already satisfied: pluggy<1.0,>=0.12 in /home/alex/.local/lib/python3.7/site-packages (from pytest->bpe->tripod-ml) (0.13.0)\n",
      "Requirement already satisfied: py>=1.5.0 in /home/alex/.local/lib/python3.7/site-packages (from pytest->bpe->tripod-ml) (1.8.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /usr/lib/python3.7/site-packages (from pytest->bpe->tripod-ml) (4.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /home/alex/.local/lib/python3.7/site-packages (from mypy->bpe->tripod-ml) (3.7.4.1)\n",
      "Requirement already satisfied: typed-ast<1.5.0,>=1.4.0 in /home/alex/.local/lib/python3.7/site-packages (from mypy->bpe->tripod-ml) (1.4.0)\n",
      "Requirement already satisfied: mypy-extensions<0.5.0,>=0.4.0 in /home/alex/.local/lib/python3.7/site-packages (from mypy->bpe->tripod-ml) (0.4.3)\n",
      "Requirement already satisfied: six in /usr/lib/python3.7/site-packages (from nltk->bpe->tripod-ml) (1.12.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/lib/python3.7/site-packages (from packaging->pytest->bpe->tripod-ml) (2.4.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/lib/python3.7/site-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest->bpe->tripod-ml) (0.6.0)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchtext.data import Field\n",
    "from torchtext.data import TabularDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "!pip3 install tripod-ml --user\n",
    "from tripod.api import Tripod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "#Change here\n",
    "DATASET='snli'\n",
    "\n",
    "tripod=Tripod()\n",
    "tripod.load('wiki-103')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelA(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(900 * 2, 600)\n",
    "        self.fc2 = nn.Linear(600, 300)\n",
    "        self.fc3 = nn.Linear(300, 100)\n",
    "        self.fc4 = nn.Linear(100, 50)\n",
    "        self.fc5 = nn.Linear(50, 3)\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.fc4(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc5(x)\n",
    "        return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelB(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_out):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_out)\n",
    "        self.gru_A = nn.GRU(input_size=emb_out, hidden_size=200, num_layers=1, bidirectional=True)\n",
    "        self.gru_B = nn.GRU(input_size=emb_out, hidden_size=200, num_layers=1, bidirectional=True)\n",
    "        self.fc = nn.Linear(800, 3)\n",
    "    def forward(self, sentA, sentB):\n",
    "        embedded_A = self.embedding(sentA)\n",
    "        embedded_B = self.embedding(sentB)\n",
    "        print(embedded_A.shape)\n",
    "        output_A, hidden_A = self.gru_A(embedded_A)\n",
    "        output_B, hidden_B = self.gru_B(embedded_B)\n",
    "        hidden_A_concat = torch.cat((hidden_A[-2,:,:], hidden_A[-1,:,:]), dim=1)\n",
    "        hidden_B_concat = torch.cat((hidden_B[-2,:,:], hidden_B[-1,:,:]), dim=1)\n",
    "        hidden = torch.cat((hidden_A_concat, hidden_B_concat), dim=1)\n",
    "\n",
    "        out = self.fc(hidden)\n",
    "        return F.softmax(out, dim=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelC(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_out):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_out)\n",
    "        self.gru_A = nn.GRU(input_size=emb_out, hidden_size=200, num_layers=1, bidirectional=True)\n",
    "        self.gru_B = nn.GRU(input_size=emb_out, hidden_size=200, num_layers=1, bidirectional=True)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(900 * 2, 600),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(600, 300),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(300, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 50),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc1 = nn.Linear(850, 3)\n",
    "    def forward(self, sentAtokens, sentBtokens, concatTripod):\n",
    "        embedded_A = self.embedding(sentAtokens)\n",
    "        embedded_B = self.embedding(sentBtokens)\n",
    "        output_A, hidden_A = self.gru_A(embedded_A)\n",
    "        output_B, hidden_B = self.gru_B(embedded_B)\n",
    "        hidden_A_concat = torch.cat((hidden_A[-2,:,:], hidden_A[-1,:,:]), dim=1)\n",
    "        hidden_B_concat = torch.cat((hidden_B[-2,:,:], hidden_B[-1,:,:]), dim=1)\n",
    "        hidden = torch.cat((hidden_A_concat, hidden_B_concat), dim=1)\n",
    "        \n",
    "        tripod_out = self.fc(concatTripod)\n",
    "        \n",
    "        print(hidden.shape)\n",
    "        print(tripod_out.shape)\n",
    "        \n",
    "        out = torch.cat((hidden, tripod_out), dim=1)\n",
    "        out = self.fc1(out)\n",
    "        return F.softmax(out, dim=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelD(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_out):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_out)\n",
    "        self.gru_A = nn.GRU(input_size=emb_out + 900, hidden_size=200, num_layers=1, bidirectional=True)\n",
    "        self.gru_B = nn.GRU(input_size=emb_out + 900, hidden_size=200, num_layers=1, bidirectional=True)\n",
    "        self.fc = nn.Linear(800, 3)\n",
    "    def forward(self, sentA, sentB, sentAtripod, sentBtripod):\n",
    "        embedded_A = self.embedding(sentA)\n",
    "        embedded_B = self.embedding(sentB)\n",
    "        \n",
    "        embedded_A = torch.cat((embedded_A, sentAtripod.repeat(embedded_A.shape[0], 1).view(embedded_A.shape[0], -1, 900)), dim=2)\n",
    "        embedded_B = torch.cat((embedded_B, sentBtripod.repeat(embedded_B.shape[0], 1).view(embedded_B.shape[0], -1, 900)), dim=2)\n",
    "\n",
    "        \n",
    "        output_A, hidden_A = self.gru_A(embedded_A)\n",
    "        output_B, hidden_B = self.gru_B(embedded_B)\n",
    "        hidden_A_concat = torch.cat((hidden_A[-2,:,:], hidden_A[-1,:,:]), dim=1)\n",
    "        hidden_B_concat = torch.cat((hidden_B[-2,:,:], hidden_B[-1,:,:]), dim=1)\n",
    "        hidden = torch.cat((hidden_A_concat, hidden_B_concat), dim=1)\n",
    "\n",
    "        out = self.fc(hidden)\n",
    "        return F.softmax(out, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET == 'sick':\n",
    "    TRAIN_PATH = './sick_train/SICK_train.txt'\n",
    "    TEST_PATH = './sick_test/SICK_test.txt'\n",
    "if DATASET == 'snli':\n",
    "    TRAIN_PATH = './snli_1.0/snli_1.0/snli_1.0_train.txt'\n",
    "    TEST_PATH = './snli_1.0/snli_1.0/snli_1.0_test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_FIELD = Field(sequential=True, tokenize=lambda x: x.split(), lower=True)  # tokenizer is identity since we already tokenized it to compute external features\n",
    "LABEL = Field(sequential=False, use_vocab=False, lower=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET == 'sick':\n",
    "    datafields = [(\"pair_ID\", None),\n",
    "                  (\"sentence_A\", TEXT_FIELD),\n",
    "                  (\"sentence_B\", TEXT_FIELD),\n",
    "                  (\"relatedness_score\", None),\n",
    "                  (\"entailment_judgment\", LABEL)]\n",
    "if DATASET == 'snli':\n",
    "    datafields = [(\"entailment_judgment\", LABEL),\n",
    "                 (\"sentence1_binary_parse\", None),\n",
    "                 (\"sentence2_binary_parse\", None),\n",
    "                 (\"sentence1_parse\", None),\n",
    "                 (\"sentence2_parse\", None),\n",
    "                 (\"sentence_A\", TEXT_FIELD),\n",
    "                 (\"sentence_B\", TEXT_FIELD),\n",
    "                 (\"captionID\", None),\n",
    "                 (\"pairID\", None),\n",
    "                 (\"label1\", None),\n",
    "                 (\"label2\", None),\n",
    "                 (\"label3\", None),\n",
    "                 (\"label4\", None),\n",
    "                 (\"label5\", None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = TabularDataset.splits(path='./data', train=TRAIN_PATH, test=TEST_PATH, skip_header=True, format='TSV', fields=datafields) \n",
    "TEXT_FIELD.build_vocab(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = {'contradiction': 0, 'neutral': 1, 'entailment': 2}\n",
    "def generate_batch_A(batch):\n",
    "    label = torch.LongTensor([LABELS[entry.entailment_judgment] for entry in batch])\n",
    "    sentence_A = [' '.join(entry.sentence_A) for entry in batch]\n",
    "    sentence_B = [' '.join(entry.sentence_B) for entry in batch]\n",
    "    return sentence_A, sentence_B, label\n",
    "\n",
    "def generate_batch_B(batch):\n",
    "    def tokens_to_tensor(tokens):\n",
    "        return torch.LongTensor([TEXT_FIELD.vocab.stoi[t] for t in tokens])\n",
    "    \n",
    "    label = torch.LongTensor([LABELS[entry.entailment_judgment] for entry in batch])\n",
    "    sentence_A = [tokens_to_tensor(entry.sentence_A) for entry in batch]\n",
    "    sentence_B = [tokens_to_tensor(entry.sentence_B) for entry in batch]\n",
    "    return sentence_A, sentence_B, label\n",
    "\n",
    "def generate_batch_C_D(batch):\n",
    "    def tokens_to_tensor(tokens):\n",
    "        return torch.LongTensor([TEXT_FIELD.vocab.stoi[t] for t in tokens])\n",
    "    \n",
    "    label = torch.LongTensor([LABELS[entry.entailment_judgment] for entry in batch])\n",
    "    full_sentence_A = [' '.join(entry.sentence_A) for entry in batch]\n",
    "    full_sentence_B = [' '.join(entry.sentence_B) for entry in batch]\n",
    "    sentence_A = [tokens_to_tensor(entry.sentence_A) for entry in batch]\n",
    "    sentence_B = [tokens_to_tensor(entry.sentence_B) for entry in batch]\n",
    "    return (sentence_A, full_sentence_A), (sentence_B, full_sentence_B), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "def train_func(dataset, model_name, model, optimizer, criterion):\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    if model_name == 'A':\n",
    "        data = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=generate_batch_A)\n",
    "    if model_name == 'B':\n",
    "        data = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=generate_batch_B)\n",
    "    if model_name == 'C' or model_name == 'D':\n",
    "        data = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=generate_batch_C_D)\n",
    "    for idx, (sentsA, sentsB, labels) in enumerate(data):\n",
    "        optimizer.zero_grad()\n",
    "        if model_name == 'A':\n",
    "            tripod_sentsA = torch.tensor(tripod(sentsA))\n",
    "            tripod_sentsB = torch.tensor(tripod(sentsB))\n",
    "            model_input = torch.cat((tripod_sentsA, tripod_sentsB), dim=1)\n",
    "            output = model(model_input)\n",
    "        if model_name == 'B':\n",
    "            sentsA = nn.utils.rnn.pad_sequence(sentsA, padding_value=TEXT_FIELD.vocab.stoi['<pad>'])\n",
    "            sentsB = nn.utils.rnn.pad_sequence(sentsB, padding_value=TEXT_FIELD.vocab.stoi['<pad>'])\n",
    "            output = model(sentsA, sentsB)\n",
    "        if model_name == 'C':\n",
    "            sentsA, fullSentsA = sentsA[0], sentsA[1]\n",
    "            sentsB, fullSentsB = sentsB[0], sentsB[1]\n",
    "            \n",
    "            sentsA = nn.utils.rnn.pad_sequence(sentsA, padding_value=TEXT_FIELD.vocab.stoi['<pad>'])\n",
    "            sentsB = nn.utils.rnn.pad_sequence(sentsB, padding_value=TEXT_FIELD.vocab.stoi['<pad>'])\n",
    "            \n",
    "            tripod_sentsA = torch.tensor(tripod(fullSentsA))\n",
    "            tripod_sentsB = torch.tensor(tripod(fullSentsB))\n",
    "            tripod_concat = torch.cat((tripod_sentsA, tripod_sentsB), dim=1)\n",
    "            \n",
    "            \n",
    "            output = model(sentsA, sentsB, tripod_concat)\n",
    "        if model_name == 'D':\n",
    "            sentsA, fullSentsA = sentsA[0], sentsA[1]\n",
    "            sentsB, fullSentsB = sentsB[0], sentsB[1]\n",
    "            sentsA = nn.utils.rnn.pad_sequence(sentsA, padding_value=TEXT_FIELD.vocab.stoi['<pad>'])\n",
    "            sentsB = nn.utils.rnn.pad_sequence(sentsB, padding_value=TEXT_FIELD.vocab.stoi['<pad>'])\n",
    "            \n",
    "            tripod_sentsA = torch.tensor(tripod(fullSentsA))\n",
    "            tripod_sentsB = torch.tensor(tripod(fullSentsB))\n",
    "            \n",
    "            output = model(sentsA, sentsB, tripod_sentsA, tripod_sentsB)\n",
    "        loss = criterion(output, labels)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_acc += (output.argmax(1) == labels).sum().item()\n",
    "    return train_loss / len(data), train_acc / len(data)\n",
    "\n",
    "def test_func(dataset, model_name, model, criterion):\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    if model_name == 'A':\n",
    "        data = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=generate_batch_A)\n",
    "    if model_name == 'B':\n",
    "        data = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=generate_batch_B)\n",
    "    if model_name == 'C' or model_name == 'D':\n",
    "        data = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=generate_batch_C_D)\n",
    "    with torch.no_grad():\n",
    "        for idx, (sentsA, sentsB, labels) in enumerate(data):\n",
    "            if model_name == 'A':\n",
    "                tripod_sentsA = torch.tensor(tripod(sentsA))\n",
    "                tripod_sentsB = torch.tensor(tripod(sentsB))\n",
    "                model_input = torch.cat((tripod_sentsA, tripod_sentsB), dim=1)\n",
    "                output = model(model_input)\n",
    "            if model_name == 'B':\n",
    "                sentsA = nn.utils.rnn.pad_sequence(sentsA, padding_value=TEXT_FIELD.vocab.stoi['<pad>'])\n",
    "                sentsB = nn.utils.rnn.pad_sequence(sentsB, padding_value=TEXT_FIELD.vocab.stoi['<pad>'])\n",
    "                output = model(sentsA, sentsB)\n",
    "            if model_name == 'C':\n",
    "                sentsA, fullSentsA = sentsA[0], sentsA[1]\n",
    "                sentsB, fullSentsB = sentsB[0], sentsB[1]\n",
    "\n",
    "                sentsA = nn.utils.rnn.pad_sequence(sentsA, padding_value=TEXT_FIELD.vocab.stoi['<pad>'])\n",
    "                sentsB = nn.utils.rnn.pad_sequence(sentsB, padding_value=TEXT_FIELD.vocab.stoi['<pad>'])\n",
    "\n",
    "                tripod_sentsA = torch.tensor(tripod(fullSentsA))\n",
    "                tripod_sentsB = torch.tensor(tripod(fullSentsB))\n",
    "                tripod_concat = torch.cat((tripod_sentsA, tripod_sentsB), dim=1)\n",
    "                \n",
    "                output = model(sentsA, sentsB, tripod_concat)\n",
    "            if model_name == 'D':\n",
    "                sentsA, fullSentsA = sentsA[0], sentsA[1]\n",
    "                sentsB, fullSentsB = sentsB[0], sentsB[1]\n",
    "                sentsA = nn.utils.rnn.pad_sequence(sentsA, padding_value=TEXT_FIELD.vocab.stoi['<pad>'])\n",
    "                sentsB = nn.utils.rnn.pad_sequence(sentsB, padding_value=TEXT_FIELD.vocab.stoi['<pad>'])\n",
    "\n",
    "                tripod_sentsA = torch.tensor(tripod(fullSentsA))\n",
    "                tripod_sentsB = torch.tensor(tripod(fullSentsB))\n",
    "\n",
    "                output = model(sentsA, sentsB, tripod_sentsA, tripod_sentsB)\n",
    "\n",
    "            loss = criterion(output, labels)\n",
    "            test_loss += loss.item()\n",
    "            test_acc += (output.argmax(1) == labels).sum().item()\n",
    "    return test_loss / len(data), test_acc / len(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1  | time in 0 minutes, 5 seconds\n",
      "\tLoss: 1.0060(train)\t|\tAcc: 100.0%(train)\n",
      "\tLoss: 1.0804(valid)\t|\tAcc: 100.0%(valid)\n",
      "Epoch: 2  | time in 0 minutes, 6 seconds\n",
      "\tLoss: 1.0060(train)\t|\tAcc: 100.0%(train)\n",
      "\tLoss: 0.9569(valid)\t|\tAcc: 100.0%(valid)\n",
      "Epoch: 3  | time in 0 minutes, 6 seconds\n",
      "\tLoss: 1.0256(train)\t|\tAcc: 100.0%(train)\n",
      "\tLoss: 0.9890(valid)\t|\tAcc: 100.0%(valid)\n",
      "Epoch: 4  | time in 0 minutes, 6 seconds\n",
      "\tLoss: 1.0256(train)\t|\tAcc: 100.0%(train)\n",
      "\tLoss: 0.5052(valid)\t|\tAcc: 100.0%(valid)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-409-cd74af34b26e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMODEL_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMODEL_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-408-721da5b1bca0>\u001b[0m in \u001b[0;36mtrain_func\u001b[0;34m(dataset, model_name, model, optimizer, criterion)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0msentsB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentsB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTEXT_FIELD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'<pad>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mtripod_sentsA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtripod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfullSentsA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0mtripod_sentsB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtripod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfullSentsB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tripod/api.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, seqs, encode_decode, batch_size, max_seq_len)\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch_x\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mencode_decode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m                     \u001b[0mrepresentation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mvec\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrepresentation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m                         \u001b[0moutput_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tripod/model.py\u001b[0m in \u001b[0;36mcompute_repr\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0minput_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;31m# summary-based embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0moutput_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_emb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0matt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcond_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_sum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;31m# GST-based embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tripod/networks/modules.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# we have a LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_packed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mGRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNNBase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_tensor\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0munsorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_impl\u001b[0;34m(self, input, hx, batch_sizes, max_batch_size, sorted_indices)\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m             result = _VF.lstm(input, hx, self._get_flat_weights(), self.bias, self.num_layers,\n\u001b[0;32m--> 526\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._get_flat_weights(), self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "N_EPOCHS = 5\n",
    "min_valid_loss = float('inf')\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=TEXT_FIELD.vocab.stoi['<pad>']).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=4.0)\n",
    "\n",
    "MODEL_NAME = 'D'\n",
    "model = ModelD(len(TEXT_FIELD.vocab.stoi), 256)\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    train_loss, train_acc = train_func(train, MODEL_NAME, model, optimizer, criterion)\n",
    "    valid_loss, valid_acc = test_func(test, MODEL_NAME, model, criterion)\n",
    "\n",
    "    secs = int(time.time() - start_time)\n",
    "    mins = secs / 60\n",
    "    secs = secs % 60\n",
    "\n",
    "    print('Epoch: %d' %(epoch + 1), \" | time in %d minutes, %d seconds\" %(mins, secs))\n",
    "    print(f'\\tLoss: {train_loss:.4f}(train)\\t|\\tAcc: {train_acc * 100:.1f}%(train)')\n",
    "    print(f'\\tLoss: {valid_loss:.4f}(valid)\\t|\\tAcc: {valid_acc * 100:.1f}%(valid)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
