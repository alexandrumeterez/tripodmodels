{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "sicksnlitraintest.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8Ja8Ccqe8djR",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchtext.data import Field\n",
        "from torchtext.data import TabularDataset\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
        "import numpy as np\n",
        "\n",
        "!pip3 install tripod-ml --user\n",
        "from tripod.api import Tripod"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "22scBup18djc",
        "colab": {}
      },
      "source": [
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)\n",
        "# Choose what dataset you want to use: sick or snli\n",
        "DATASET='snli'\n",
        "\n",
        "tripod=Tripod(device=device)\n",
        "tripod.load('wiki-103')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NLeRJg5_8djl",
        "colab": {}
      },
      "source": [
        "import os\n",
        "if not os.path.exists(\"./data\"):\n",
        "    !mkdir data\n",
        "\n",
        "if DATASET == 'snli':\n",
        "    !wget -P data \"https://nlp.stanford.edu/projects/snli/snli_1.0.zip\"\n",
        "    !unzip -d data/snli_1.0 data/snli_1.0.zip\n",
        "if DATASET == \"sick\":\n",
        "    !wget -P data \"http://alt.qcri.org/semeval2014/task1/data/uploads/sick_train.zip\"\n",
        "    !wget -P data \"http://alt.qcri.org/semeval2014/task1/data/uploads/sick_test_annotated.zip\"\n",
        "    !unzip -d data/sick_train data/sick_train.zip\n",
        "    !unzip -d data/sick_test_annotated data/sick_test_annotated.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W5m6nGeu8djt",
        "colab": {}
      },
      "source": [
        "# Models from the Tripod paper\n",
        "class ModelA(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(900 * 2, 600)\n",
        "        self.fc2 = nn.Linear(600, 300)\n",
        "        self.fc3 = nn.Linear(300, 100)\n",
        "        self.fc4 = nn.Linear(100, 50)\n",
        "        self.fc5 = nn.Linear(50, 3)\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "        # x = F.dropout(x, 0.8)\n",
        "\n",
        "        x = self.fc3(x)\n",
        "        x = F.relu(x)\n",
        "        # x = F.dropout(x, 0.8)\n",
        "\n",
        "        x = self.fc4(x)\n",
        "        x = F.relu(x)\n",
        "        # x = F.dropout(x, 0.8)\n",
        "        x = self.fc5(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ll6kb-Zg8dj3",
        "colab": {}
      },
      "source": [
        "class ModelB(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_out):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_out)\n",
        "        self.gru_A = nn.GRU(input_size=emb_out, hidden_size=200, num_layers=1, bidirectional=True)\n",
        "        self.gru_B = nn.GRU(input_size=emb_out, hidden_size=200, num_layers=1, bidirectional=True)\n",
        "        self.fc = nn.Linear(800, 3)\n",
        "    def forward(self, sentA, sentB):\n",
        "        embedded_A = self.embedding(sentA)\n",
        "        embedded_B = self.embedding(sentB)\n",
        "        output_A, hidden_A = self.gru_A(embedded_A)\n",
        "        output_B, hidden_B = self.gru_B(embedded_B)\n",
        "        hidden_A_concat = torch.cat((hidden_A[-2,:,:], hidden_A[-1,:,:]), dim=1)\n",
        "        hidden_B_concat = torch.cat((hidden_B[-2,:,:], hidden_B[-1,:,:]), dim=1)\n",
        "        hidden = torch.cat((hidden_A_concat, hidden_B_concat), dim=1)\n",
        "\n",
        "        out = self.fc(hidden)\n",
        "        return F.relu(out)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OYJVs-tv8dj_",
        "colab": {}
      },
      "source": [
        "class ModelC(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_out):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_out)\n",
        "        self.gru_A = nn.GRU(input_size=emb_out, hidden_size=200, num_layers=1, bidirectional=True)\n",
        "        self.gru_B = nn.GRU(input_size=emb_out, hidden_size=200, num_layers=1, bidirectional=True)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(900 * 2, 600),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(600, 300),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(300, 100),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(100, 50),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.fc1 = nn.Linear(850, 3)\n",
        "    def forward(self, sentAtokens, sentBtokens, concatTripod):\n",
        "        embedded_A = self.embedding(sentAtokens)\n",
        "        embedded_B = self.embedding(sentBtokens)\n",
        "        output_A, hidden_A = self.gru_A(embedded_A)\n",
        "        output_B, hidden_B = self.gru_B(embedded_B)\n",
        "        hidden_A_concat = torch.cat((hidden_A[-2,:,:], hidden_A[-1,:,:]), dim=1)\n",
        "        hidden_B_concat = torch.cat((hidden_B[-2,:,:], hidden_B[-1,:,:]), dim=1)\n",
        "        hidden = torch.cat((hidden_A_concat, hidden_B_concat), dim=1)\n",
        "        \n",
        "        tripod_out = self.fc(concatTripod)\n",
        "        \n",
        "        out = torch.cat((hidden, tripod_out), dim=1)\n",
        "        out = self.fc1(out)\n",
        "        return F.relu(out)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_IqqowUq8dkH",
        "colab": {}
      },
      "source": [
        "class ModelD(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_out):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_out)\n",
        "        self.gru_A = nn.GRU(input_size=emb_out + 900, hidden_size=200, num_layers=1, bidirectional=True)\n",
        "        self.gru_B = nn.GRU(input_size=emb_out + 900, hidden_size=200, num_layers=1, bidirectional=True)\n",
        "        self.fc = nn.Linear(800, 3)\n",
        "    def forward(self, sentA, sentB, sentAtripod, sentBtripod):\n",
        "        embedded_A = self.embedding(sentA)\n",
        "        embedded_B = self.embedding(sentB)\n",
        "        \n",
        "        embedded_A = torch.cat((embedded_A, sentAtripod.repeat(embedded_A.shape[0], 1).view(embedded_A.shape[0], -1, 900)), dim=2)\n",
        "        embedded_B = torch.cat((embedded_B, sentBtripod.repeat(embedded_B.shape[0], 1).view(embedded_B.shape[0], -1, 900)), dim=2)\n",
        "\n",
        "        output_A, hidden_A = self.gru_A(embedded_A)\n",
        "        output_B, hidden_B = self.gru_B(embedded_B)\n",
        "        hidden_A_concat = torch.cat((hidden_A[-2,:,:], hidden_A[-1,:,:]), dim=1)\n",
        "        hidden_B_concat = torch.cat((hidden_B[-2,:,:], hidden_B[-1,:,:]), dim=1)\n",
        "        hidden = torch.cat((hidden_A_concat, hidden_B_concat), dim=1)\n",
        "\n",
        "        out = self.fc(hidden)\n",
        "        return F.relu(out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RJXU3Ae28dkO",
        "colab": {}
      },
      "source": [
        "if DATASET == 'sick':\n",
        "    TRAIN_PATH = './sick_train/SICK_train.txt'\n",
        "    TEST_PATH = './sick_test_annotated/SICK_test_annotated.txt'\n",
        "if DATASET == 'snli':\n",
        "    TRAIN_PATH = './snli_1.0/snli_1.0/snli_1.0_train.txt'\n",
        "    TEST_PATH = './snli_1.0/snli_1.0/snli_1.0_test.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XEvG-8jk8dkW",
        "colab": {}
      },
      "source": [
        "TEXT_FIELD = Field(sequential=True, tokenize=lambda x: x.split(), lower=True)\n",
        "LABEL = Field(sequential=False, use_vocab=False, lower=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mecdwYHu8dkk",
        "colab": {}
      },
      "source": [
        "if DATASET == 'sick':\n",
        "    datafields = [(\"pair_ID\", None),\n",
        "                  (\"sentence_A\", TEXT_FIELD),\n",
        "                  (\"sentence_B\", TEXT_FIELD),\n",
        "                  (\"relatedness_score\", None),\n",
        "                  (\"entailment_judgment\", LABEL)]\n",
        "if DATASET == 'snli':\n",
        "    datafields = [(\"entailment_judgment\", LABEL),\n",
        "                 (\"sentence1_binary_parse\", None),\n",
        "                 (\"sentence2_binary_parse\", None),\n",
        "                 (\"sentence1_parse\", None),\n",
        "                 (\"sentence2_parse\", None),\n",
        "                 (\"sentence_A\", TEXT_FIELD),\n",
        "                 (\"sentence_B\", TEXT_FIELD),\n",
        "                 (\"captionID\", None),\n",
        "                 (\"pairID\", None),\n",
        "                 (\"label1\", None),\n",
        "                 (\"label2\", None),\n",
        "                 (\"label3\", None),\n",
        "                 (\"label4\", None),\n",
        "                 (\"label5\", None)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Bs486olN8dks",
        "colab": {}
      },
      "source": [
        "# Load the data into memory and build the vocabulary\n",
        "train, test = TabularDataset.splits(path='./data', train=TRAIN_PATH, test=TEST_PATH, skip_header=True, format='TSV', fields=datafields, filter_pred=lambda x: x.entailment_judgment!='-') \n",
        "TEXT_FIELD.build_vocab(train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vW882A5_8dkz",
        "colab": {}
      },
      "source": [
        "def append_tripod_vectors(dataset):\n",
        "    n_examples = len(dataset)\n",
        "    \n",
        "    all_sentences_A = list(map(lambda x: ' '.join(x.sentence_A), dataset))\n",
        "    all_sentences_B = list(map(lambda x: ' '.join(x.sentence_B), dataset))\n",
        "\n",
        "    print(\"Calculating tripod vectors for sentences A\")\n",
        "    sentences_A_tripod = tripod(all_sentences_A, batch_size=512)\n",
        "    print(\"Calculating tripod vectors for sentences B\")\n",
        "    sentences_B_tripod = tripod(all_sentences_B, batch_size=512)\n",
        "    \n",
        "    print(\"Appending to dataset\")\n",
        "    for i in range(n_examples):\n",
        "        dataset[i].sentence_A_tripod = sentences_A_tripod[i]\n",
        "        dataset[i].sentence_B_tripod = sentences_B_tripod[i]\n",
        "    return dataset\n",
        "\n",
        "train, test = append_tripod_vectors(train), append_tripod_vectors(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mJGiH4H28dk8",
        "colab": {}
      },
      "source": [
        "LABELS = {'contradiction': 0, 'neutral': 1, 'entailment': 2}\n",
        "def tokens_to_tensor(tokens):\n",
        "        return torch.LongTensor([TEXT_FIELD.vocab.stoi[t] for t in tokens])\n",
        "    \n",
        "def generate_batch(batch):\n",
        "    label = torch.LongTensor([LABELS[entry.entailment_judgment] for entry in batch])\n",
        "    sentence_A = [tokens_to_tensor(entry.sentence_A) for entry in batch]\n",
        "    sentence_B = [tokens_to_tensor(entry.sentence_B) for entry in batch]\n",
        "    sentence_A_tripod = [entry.sentence_A_tripod for entry in batch]\n",
        "    sentence_B_tripod = [entry.sentence_B_tripod for entry in batch]\n",
        "    \n",
        "    return sentence_A, sentence_A_tripod, sentence_B, sentence_B_tripod, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UB5yw4kU8dlC",
        "colab": {}
      },
      "source": [
        "# Balance weights\n",
        "\n",
        "# train = train[:1000]\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "def make_weights_for_balanced_classes(dataset):\n",
        "    count = [0] * 3\n",
        "    \n",
        "    labels = list(map(lambda x: x.entailment_judgment, dataset))\n",
        "    count[0] = labels.count('contradiction')\n",
        "    count[1] = labels.count('neutral')\n",
        "    count[2] = labels.count('entailment')\n",
        "    N = float(sum(count))\n",
        "    weight_per_class = N / np.array(count)\n",
        "    weight = [0] * len(dataset)\n",
        "    for idx, val in enumerate(dataset):\n",
        "        weight[idx] = weight_per_class[LABELS[val.entailment_judgment]]\n",
        "    return weight\n",
        "\n",
        "train_w = make_weights_for_balanced_classes(train)\n",
        "test_w = make_weights_for_balanced_classes(test)\n",
        "train_sampler = WeightedRandomSampler(train_w, len(train_w))\n",
        "test_sampler = WeightedRandomSampler(test_w, len(test_w))\n",
        "\n",
        "def train_func(dataset, model_name, model, optimizer, criterion, BATCH_SIZE):\n",
        "    train_loss = 0\n",
        "    train_acc = 0\n",
        "    model.train()\n",
        "    data = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=generate_batch)#, sampler=train_sampler)\n",
        "    for idx, (sentsA, sents_A_tripod, sentsB, sents_B_tripod, labels) in enumerate(data):\n",
        "        model.zero_grad()\n",
        "        labels = labels.to(device)\n",
        "        if model_name == 'A':\n",
        "            tripod_sentsA = torch.tensor(sents_A_tripod).to(device)\n",
        "            tripod_sentsB = torch.tensor(sents_B_tripod).to(device)\n",
        "            model_input = torch.cat((tripod_sentsA, tripod_sentsB), dim=1).to(device)\n",
        "            output = model(model_input)\n",
        "        if model_name == 'B':\n",
        "            sentsA = nn.utils.rnn.pad_sequence(sentsA, padding_value=TEXT_FIELD.vocab.stoi['<pad>']).to(device)\n",
        "            sentsB = nn.utils.rnn.pad_sequence(sentsB, padding_value=TEXT_FIELD.vocab.stoi['<pad>']).to(device)\n",
        "            output = model(sentsA, sentsB)\n",
        "        if model_name == 'C':\n",
        "            sentsA = nn.utils.rnn.pad_sequence(sentsA, padding_value=TEXT_FIELD.vocab.stoi['<pad>']).to(device)\n",
        "            sentsB = nn.utils.rnn.pad_sequence(sentsB, padding_value=TEXT_FIELD.vocab.stoi['<pad>']).to(device)\n",
        "            tripod_sentsA = torch.tensor(sents_A_tripod).to(device)\n",
        "            tripod_sentsB = torch.tensor(sents_B_tripod).to(device)\n",
        "            tripod_concat = torch.cat((tripod_sentsA, tripod_sentsB), dim=1).to(device)\n",
        "            output = model(sentsA, sentsB, tripod_concat)\n",
        "        if model_name == 'D':\n",
        "            sentsA = nn.utils.rnn.pad_sequence(sentsA, padding_value=TEXT_FIELD.vocab.stoi['<pad>']).to(device)\n",
        "            sentsB = nn.utils.rnn.pad_sequence(sentsB, padding_value=TEXT_FIELD.vocab.stoi['<pad>']).to(device)\n",
        "            tripod_sentsA = torch.tensor(sents_A_tripod).to(device)\n",
        "            tripod_sentsB = torch.tensor(sents_B_tripod).to(device)\n",
        "            output = model(sentsA, sentsB, tripod_sentsA, tripod_sentsB)\n",
        "        loss = criterion(output, labels)\n",
        "        train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_acc += ((output.argmax(1) == labels).sum().item())\n",
        "    return train_loss / len(dataset), train_acc / len(dataset)\n",
        "\n",
        "def test_func(dataset, model_name, model, criterion, BATCH_SIZE):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    test_acc = 0\n",
        "    data = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=generate_batch, sampler=test_sampler)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (sentsA, sents_A_tripod, sentsB, sents_B_tripod, labels) in enumerate(data):\n",
        "            labels = labels.to(device)\n",
        "            if model_name == 'A':\n",
        "                tripod_sentsA = torch.tensor(sents_A_tripod).to(device)\n",
        "                tripod_sentsB = torch.tensor(sents_B_tripod).to(device)\n",
        "                model_input = torch.cat((tripod_sentsA, tripod_sentsB), dim=1).to(device)\n",
        "                output = model(model_input)\n",
        "            if model_name == 'B':\n",
        "                sentsA = nn.utils.rnn.pad_sequence(sentsA, padding_value=TEXT_FIELD.vocab.stoi['<pad>']).to(device)\n",
        "                sentsB = nn.utils.rnn.pad_sequence(sentsB, padding_value=TEXT_FIELD.vocab.stoi['<pad>']).to(device)\n",
        "                output = model(sentsA, sentsB)\n",
        "            if model_name == 'C':\n",
        "                sentsA = nn.utils.rnn.pad_sequence(sentsA, padding_value=TEXT_FIELD.vocab.stoi['<pad>']).to(device)\n",
        "                sentsB = nn.utils.rnn.pad_sequence(sentsB, padding_value=TEXT_FIELD.vocab.stoi['<pad>']).to(device)\n",
        "                tripod_sentsA = torch.tensor(sents_A_tripod).to(device)\n",
        "                tripod_sentsB = torch.tensor(sents_B_tripod).to(device)\n",
        "                tripod_concat = torch.cat((tripod_sentsA, tripod_sentsB), dim=1).to(device)\n",
        "                output = model(sentsA, sentsB, tripod_concat)\n",
        "            if model_name == 'D':\n",
        "                sentsA = nn.utils.rnn.pad_sequence(sentsA, padding_value=TEXT_FIELD.vocab.stoi['<pad>']).to(device)\n",
        "                sentsB = nn.utils.rnn.pad_sequence(sentsB, padding_value=TEXT_FIELD.vocab.stoi['<pad>']).to(device)\n",
        "                tripod_sentsA = torch.tensor(sents_A_tripod).to(device)\n",
        "                tripod_sentsB = torch.tensor(sents_B_tripod).to(device)\n",
        "                output = model(sentsA, sentsB, tripod_sentsA, tripod_sentsB)\n",
        "\n",
        "            loss = criterion(output, labels)\n",
        "            test_loss += loss.item()\n",
        "            test_acc += (output.argmax(1) == labels).sum().item()\n",
        "    return test_loss / len(dataset), test_acc / len(dataset)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0v7Rky_Z8dlK",
        "colab": {}
      },
      "source": [
        "import time\n",
        "N_EPOCHS = 2000\n",
        "min_valid_loss = float('inf')\n",
        "\n",
        "MODEL_NAME = 'C'\n",
        "VOCAB_SIZE = len(TEXT_FIELD.vocab.stoi)\n",
        "EMB_OUT_DIM = 256\n",
        "LEARNING_RATE = 0.1\n",
        "\n",
        "if MODEL_NAME == 'A':\n",
        "    model = ModelA().to(device)\n",
        "elif MODEL_NAME == 'B':\n",
        "    model = ModelB(VOCAB_SIZE, EMB_OUT_DIM).to(device)\n",
        "elif MODEL_NAME == 'C':\n",
        "    model = ModelC(VOCAB_SIZE, EMB_OUT_DIM).to(device)\n",
        "elif MODEL_NAME == 'D':\n",
        "    model = ModelD(VOCAB_SIZE, EMB_OUT_DIM).to(device)\n",
        "\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    train_loss, train_acc = train_func(train, MODEL_NAME, model, optimizer, criterion, BATCH_SIZE)\n",
        "    test_loss, test_acc = test_func(test, MODEL_NAME, model, criterion, BATCH_SIZE)\n",
        "\n",
        "    secs = int(time.time() - start_time)\n",
        "    mins = secs / 60\n",
        "    secs = secs % 60\n",
        "\n",
        "    print('Epoch: %d' %(epoch + 1), \" | time in %d minutes, %d seconds\" %(mins, secs))\n",
        "    print(f'\\tLoss: {train_loss:.4f}(train)\\t|\\tAcc: {train_acc * 100:.1f}%(train)')\n",
        "    print(f'\\tLoss: {test_loss:.4f}(test)\\t|\\tAcc: {test_acc * 100:.1f}%(test)')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xKnNwpDbzdv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}