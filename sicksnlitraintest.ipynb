{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchtext.data import Field\n",
    "from torchtext.data import TabularDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "!pip3 install tripod-ml --user\n",
    "from tripod.api import Tripod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Choose what dataset you want to use: sick or snli\n",
    "DATASET='snli'\n",
    "\n",
    "tripod=Tripod(device=device)\n",
    "tripod.load('wiki-103')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"./data\"):\n",
    "    !mkdir data\n",
    "\n",
    "if DATASET == 'snli':\n",
    "    !wget -P data \"https://nlp.stanford.edu/projects/snli/snli_1.0.zip\"\n",
    "    !unzip -d data/snli_1.0 data/snli_1.0.zip\n",
    "if DATASET == \"sick\":\n",
    "    !wget -P data \"http://alt.qcri.org/semeval2014/task1/data/uploads/sick_train.zip\"\n",
    "    !wget -P data \"http://alt.qcri.org/semeval2014/task1/data/uploads/sick_test_annotated.zip\"\n",
    "    !unzip -d data/sick_train data/sick_train.zip\n",
    "    !unzip -d data/sick_test_annotated data/sick_test_annotated.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models from the Tripod paper\n",
    "class ModelA(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(900 * 2, 600)\n",
    "        self.fc2 = nn.Linear(600, 300)\n",
    "        self.fc3 = nn.Linear(300, 100)\n",
    "        self.fc4 = nn.Linear(100, 50)\n",
    "        self.fc5 = nn.Linear(50, 3)\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.fc4(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc5(x)\n",
    "        return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelB(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_out):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_out)\n",
    "        self.gru_A = nn.GRU(input_size=emb_out, hidden_size=200, num_layers=1, bidirectional=True)\n",
    "        self.gru_B = nn.GRU(input_size=emb_out, hidden_size=200, num_layers=1, bidirectional=True)\n",
    "        self.fc = nn.Linear(800, 3)\n",
    "    def forward(self, sentA, sentB):\n",
    "        embedded_A = self.embedding(sentA)\n",
    "        embedded_B = self.embedding(sentB)\n",
    "        output_A, hidden_A = self.gru_A(embedded_A)\n",
    "        output_B, hidden_B = self.gru_B(embedded_B)\n",
    "        hidden_A_concat = torch.cat((hidden_A[-2,:,:], hidden_A[-1,:,:]), dim=1)\n",
    "        hidden_B_concat = torch.cat((hidden_B[-2,:,:], hidden_B[-1,:,:]), dim=1)\n",
    "        hidden = torch.cat((hidden_A_concat, hidden_B_concat), dim=1)\n",
    "\n",
    "        out = self.fc(hidden)\n",
    "        return F.softmax(out, dim=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelC(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_out):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_out)\n",
    "        self.gru_A = nn.GRU(input_size=emb_out, hidden_size=200, num_layers=1, bidirectional=True)\n",
    "        self.gru_B = nn.GRU(input_size=emb_out, hidden_size=200, num_layers=1, bidirectional=True)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(900 * 2, 600),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(600, 300),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(300, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 50),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc1 = nn.Linear(850, 3)\n",
    "    def forward(self, sentAtokens, sentBtokens, concatTripod):\n",
    "        embedded_A = self.embedding(sentAtokens)\n",
    "        embedded_B = self.embedding(sentBtokens)\n",
    "        output_A, hidden_A = self.gru_A(embedded_A)\n",
    "        output_B, hidden_B = self.gru_B(embedded_B)\n",
    "        hidden_A_concat = torch.cat((hidden_A[-2,:,:], hidden_A[-1,:,:]), dim=1)\n",
    "        hidden_B_concat = torch.cat((hidden_B[-2,:,:], hidden_B[-1,:,:]), dim=1)\n",
    "        hidden = torch.cat((hidden_A_concat, hidden_B_concat), dim=1)\n",
    "        \n",
    "        tripod_out = self.fc(concatTripod)\n",
    "        \n",
    "        out = torch.cat((hidden, tripod_out), dim=1)\n",
    "        out = self.fc1(out)\n",
    "        return F.softmax(out, dim=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelD(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_out):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_out)\n",
    "        self.gru_A = nn.GRU(input_size=emb_out + 900, hidden_size=200, num_layers=1, bidirectional=True)\n",
    "        self.gru_B = nn.GRU(input_size=emb_out + 900, hidden_size=200, num_layers=1, bidirectional=True)\n",
    "        self.fc = nn.Linear(800, 3)\n",
    "    def forward(self, sentA, sentB, sentAtripod, sentBtripod):\n",
    "        embedded_A = self.embedding(sentA)\n",
    "        embedded_B = self.embedding(sentB)\n",
    "        \n",
    "        embedded_A = torch.cat((embedded_A, sentAtripod.repeat(embedded_A.shape[0], 1).view(embedded_A.shape[0], -1, 900)), dim=2)\n",
    "        embedded_B = torch.cat((embedded_B, sentBtripod.repeat(embedded_B.shape[0], 1).view(embedded_B.shape[0], -1, 900)), dim=2)\n",
    "\n",
    "        \n",
    "        output_A, hidden_A = self.gru_A(embedded_A)\n",
    "        output_B, hidden_B = self.gru_B(embedded_B)\n",
    "        hidden_A_concat = torch.cat((hidden_A[-2,:,:], hidden_A[-1,:,:]), dim=1)\n",
    "        hidden_B_concat = torch.cat((hidden_B[-2,:,:], hidden_B[-1,:,:]), dim=1)\n",
    "        hidden = torch.cat((hidden_A_concat, hidden_B_concat), dim=1)\n",
    "\n",
    "        out = self.fc(hidden)\n",
    "        return F.softmax(out, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET == 'sick':\n",
    "    TRAIN_PATH = './sick_train/SICK_train.txt'\n",
    "    TEST_PATH = './sick_test_annotated/SICK_test_annotated.txt'\n",
    "if DATASET == 'snli':\n",
    "    TRAIN_PATH = './snli_1.0/snli_1.0/snli_1.0_train.txt'\n",
    "    TEST_PATH = './snli_1.0/snli_1.0/snli_1.0_test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_FIELD = Field(sequential=True, tokenize=lambda x: x.split(), lower=True)  # tokenizer is identity since we already tokenized it to compute external features\n",
    "LABEL = Field(sequential=False, use_vocab=False, lower=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET == 'sick':\n",
    "    datafields = [(\"pair_ID\", None),\n",
    "                  (\"sentence_A\", TEXT_FIELD),\n",
    "                  (\"sentence_B\", TEXT_FIELD),\n",
    "                  (\"relatedness_score\", None),\n",
    "                  (\"entailment_judgment\", LABEL)]\n",
    "if DATASET == 'snli':\n",
    "    datafields = [(\"entailment_judgment\", LABEL),\n",
    "                 (\"sentence1_binary_parse\", None),\n",
    "                 (\"sentence2_binary_parse\", None),\n",
    "                 (\"sentence1_parse\", None),\n",
    "                 (\"sentence2_parse\", None),\n",
    "                 (\"sentence_A\", TEXT_FIELD),\n",
    "                 (\"sentence_B\", TEXT_FIELD),\n",
    "                 (\"captionID\", None),\n",
    "                 (\"pairID\", None),\n",
    "                 (\"label1\", None),\n",
    "                 (\"label2\", None),\n",
    "                 (\"label3\", None),\n",
    "                 (\"label4\", None),\n",
    "                 (\"label5\", None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data into memory and build the vocabulary\n",
    "train, test = TabularDataset.splits(path='./data', train=TRAIN_PATH, test=TEST_PATH, skip_header=True, format='TSV', fields=datafields, filter_pred=lambda x: x.entailment_judgment!='-') \n",
    "TEXT_FIELD.build_vocab(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = {'contradiction': 0, 'neutral': 1, 'entailment': 2}\n",
    "# Functions to build batches for the different models since each a different batch type\n",
    "def generate_batch_A(batch):\n",
    "    label = torch.LongTensor([LABELS[entry.entailment_judgment] for entry in batch])\n",
    "    sentence_A = [' '.join(entry.sentence_A) for entry in batch]\n",
    "    sentence_B = [' '.join(entry.sentence_B) for entry in batch]\n",
    "    return sentence_A, sentence_B, label\n",
    "\n",
    "def generate_batch_B(batch):\n",
    "    def tokens_to_tensor(tokens):\n",
    "        return torch.LongTensor([TEXT_FIELD.vocab.stoi[t] for t in tokens])\n",
    "    \n",
    "    label = torch.LongTensor([LABELS[entry.entailment_judgment] for entry in batch])\n",
    "    sentence_A = [tokens_to_tensor(entry.sentence_A) for entry in batch]\n",
    "    sentence_B = [tokens_to_tensor(entry.sentence_B) for entry in batch]\n",
    "    return sentence_A, sentence_B, label\n",
    "\n",
    "def generate_batch_C_D(batch):\n",
    "    def tokens_to_tensor(tokens):\n",
    "        return torch.LongTensor([TEXT_FIELD.vocab.stoi[t] for t in tokens])\n",
    "    label = torch.LongTensor([LABELS.get(entry.entailment_judgment, 0) for entry in batch])\n",
    "    full_sentence_A = [' '.join(entry.sentence_A) for entry in batch]\n",
    "    full_sentence_B = [' '.join(entry.sentence_B) for entry in batch]\n",
    "    sentence_A = [tokens_to_tensor(entry.sentence_A) for entry in batch]\n",
    "    sentence_B = [tokens_to_tensor(entry.sentence_B) for entry in batch]\n",
    "    return (sentence_A, full_sentence_A), (sentence_B, full_sentence_B), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_func(dataset, model_name, model, optimizer, criterion, BATCH_SIZE):\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    if model_name == 'A':\n",
    "        data = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=generate_batch_A)\n",
    "    if model_name == 'B':\n",
    "        data = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=generate_batch_B)\n",
    "    if model_name == 'C' or model_name == 'D':\n",
    "        data = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=generate_batch_C_D)\n",
    "    for idx, (sentsA, sentsB, labels) in enumerate(data):\n",
    "        optimizer.zero_grad()\n",
    "        if model_name == 'A':\n",
    "            tripod_sentsA = torch.tensor(tripod(sentsA, batch_size=BATCH_SIZE)).to(device)\n",
    "            tripod_sentsB = torch.tensor(tripod(sentsB, batch_size=BATCH_SIZE)).to(device)\n",
    "            model_input = torch.cat((tripod_sentsA, tripod_sentsB), dim=1).to(device)\n",
    "            output = model(model_input)\n",
    "        if model_name == 'B':\n",
    "            sentsA = nn.utils.rnn.pad_sequence(sentsA, padding_value=TEXT_FIELD.vocab.stoi['<pad>']).to(device)\n",
    "            sentsB = nn.utils.rnn.pad_sequence(sentsB, padding_value=TEXT_FIELD.vocab.stoi['<pad>']).to(device)\n",
    "            output = model(sentsA, sentsB)\n",
    "        if model_name == 'C':\n",
    "            sentsA, fullSentsA = sentsA[0], sentsA[1]\n",
    "            sentsB, fullSentsB = sentsB[0], sentsB[1]\n",
    "            \n",
    "            sentsA = nn.utils.rnn.pad_sequence(sentsA, padding_value=TEXT_FIELD.vocab.stoi['<pad>']).to(device)\n",
    "            sentsB = nn.utils.rnn.pad_sequence(sentsB, padding_value=TEXT_FIELD.vocab.stoi['<pad>']).to(device)\n",
    "            \n",
    "            tripod_sentsA = torch.tensor(tripod(fullSentsA, batch_size=BATCH_SIZE)).to(device)\n",
    "            tripod_sentsB = torch.tensor(tripod(fullSentsB, batch_size=BATCH_SIZE)).to(device)\n",
    "            tripod_concat = torch.cat((tripod_sentsA, tripod_sentsB), dim=1).to(device)\n",
    "            \n",
    "            \n",
    "            output = model(sentsA, sentsB, tripod_concat)\n",
    "        if model_name == 'D':\n",
    "            sentsA, fullSentsA = sentsA[0], sentsA[1]\n",
    "            sentsB, fullSentsB = sentsB[0], sentsB[1]\n",
    "            sentsA = nn.utils.rnn.pad_sequence(sentsA, padding_value=TEXT_FIELD.vocab.stoi['<pad>']).to(device)\n",
    "            sentsB = nn.utils.rnn.pad_sequence(sentsB, padding_value=TEXT_FIELD.vocab.stoi['<pad>']).to(device)\n",
    "            \n",
    "            tripod_sentsA = torch.tensor(tripod(fullSentsA, batch_size=BATCH_SIZE)).to(device)\n",
    "            tripod_sentsB = torch.tensor(tripod(fullSentsB, batch_size=BATCH_SIZE)).to(device)\n",
    "            \n",
    "            output = model(sentsA, sentsB, tripod_sentsA, tripod_sentsB)\n",
    "        loss = criterion(output, labels)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_acc += (output.argmax(1) == labels).sum().item()\n",
    "    return train_loss / len(data), train_acc / len(data)\n",
    "\n",
    "def test_func(dataset, model_name, model, criterion, BATCH_SIZE):\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    if model_name == 'A':\n",
    "        data = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=generate_batch_A)\n",
    "    if model_name == 'B':\n",
    "        data = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=generate_batch_B)\n",
    "    if model_name == 'C' or model_name == 'D':\n",
    "        data = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=generate_batch_C_D)\n",
    "    with torch.no_grad():\n",
    "        for idx, (sentsA, sentsB, labels) in enumerate(data):\n",
    "            if model_name == 'A':\n",
    "                tripod_sentsA = torch.tensor(tripod(sentsA, batch_size=BATCH_SIZE)).to(device)\n",
    "                tripod_sentsB = torch.tensor(tripod(sentsB, batch_size=BATCH_SIZE)).to(device)\n",
    "                model_input = torch.cat((tripod_sentsA, tripod_sentsB), dim=1).to(device)\n",
    "                output = model(model_input)\n",
    "            if model_name == 'B':\n",
    "                sentsA = nn.utils.rnn.pad_sequence(sentsA, padding_value=TEXT_FIELD.vocab.stoi['<pad>']).to(device)\n",
    "                sentsB = nn.utils.rnn.pad_sequence(sentsB, padding_value=TEXT_FIELD.vocab.stoi['<pad>']).to(device)\n",
    "                output = model(sentsA, sentsB)\n",
    "            if model_name == 'C':\n",
    "                sentsA, fullSentsA = sentsA[0], sentsA[1]\n",
    "                sentsB, fullSentsB = sentsB[0], sentsB[1]\n",
    "\n",
    "                sentsA = nn.utils.rnn.pad_sequence(sentsA, padding_value=TEXT_FIELD.vocab.stoi['<pad>']).to(device)\n",
    "                sentsB = nn.utils.rnn.pad_sequence(sentsB, padding_value=TEXT_FIELD.vocab.stoi['<pad>']).to(device)\n",
    "\n",
    "                tripod_sentsA = torch.tensor(tripod(fullSentsA, batch_size=BATCH_SIZE)).to(device)\n",
    "                tripod_sentsB = torch.tensor(tripod(fullSentsB, batch_size=BATCH_SIZE)).to(device)\n",
    "                tripod_concat = torch.cat((tripod_sentsA, tripod_sentsB), dim=1).to(device)\n",
    "                \n",
    "                output = model(sentsA, sentsB, tripod_concat)\n",
    "            if model_name == 'D':\n",
    "                sentsA, fullSentsA = sentsA[0], sentsA[1]\n",
    "                sentsB, fullSentsB = sentsB[0], sentsB[1]\n",
    "                sentsA = nn.utils.rnn.pad_sequence(sentsA, padding_value=TEXT_FIELD.vocab.stoi['<pad>']).to(device)\n",
    "                sentsB = nn.utils.rnn.pad_sequence(sentsB, padding_value=TEXT_FIELD.vocab.stoi['<pad>']).to(device)\n",
    "\n",
    "                tripod_sentsA = torch.tensor(tripod(fullSentsA, batch_size=BATCH_SIZE)).to(device)\n",
    "                tripod_sentsB = torch.tensor(tripod(fullSentsB, batch_size=BATCH_SIZE)).to(device)\n",
    "\n",
    "                output = model(sentsA, sentsB, tripod_sentsA, tripod_sentsB)\n",
    "\n",
    "            loss = criterion(output, labels)\n",
    "            test_loss += loss.item()\n",
    "            test_acc += (output.argmax(1) == labels).sum().item()\n",
    "    return test_loss / len(data), test_acc / len(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "N_EPOCHS = 5\n",
    "min_valid_loss = float('inf')\n",
    "\n",
    "MODEL_NAME = 'A'\n",
    "VOCAB_SIZE = len(TEXT_FIELD.vocab.stoi)\n",
    "EMB_OUT_DIM = 256\n",
    "LEARNING_RATE = 0.01\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "if MODEL_NAME == 'A':\n",
    "    model = ModelA().to(device)\n",
    "elif MODEL_NAME == 'B':\n",
    "    model = ModelB(VOCAB_SIZE, EMB_OUT_DIM).to(device)\n",
    "elif MODEL_NAME == 'C':\n",
    "    model = ModelC(VOCAB_SIZE, EMB_OUT_DIM).to(device)\n",
    "elif MODEL_NAME == 'D':\n",
    "    model = ModelD(VOCAB_SIZE, EMB_OUT_DIM).to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=TEXT_FIELD.vocab.stoi['<pad>']).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    train_loss, train_acc = train_func(train, MODEL_NAME, model, optimizer, criterion, BATCH_SIZE)\n",
    "    valid_loss, valid_acc = test_func(test, MODEL_NAME, model, criterion, BATCH_SIZE)\n",
    "\n",
    "    secs = int(time.time() - start_time)\n",
    "    mins = secs / 60\n",
    "    secs = secs % 60\n",
    "\n",
    "    print('Epoch: %d' %(epoch + 1), \" | time in %d minutes, %d seconds\" %(mins, secs))\n",
    "    print(f'\\tLoss: {train_loss:.4f}(train)\\t|\\tAcc: {train_acc * 100:.1f}%(train)')\n",
    "    print(f'\\tLoss: {valid_loss:.4f}(valid)\\t|\\tAcc: {valid_acc * 100:.1f}%(valid)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
