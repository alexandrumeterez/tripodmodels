{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 504
    },
    "colab_type": "code",
    "id": "8Ja8Ccqe8djR",
    "outputId": "ec2c9f16-1680-458d-8023-3426f4a40df9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tripod-ml in /root/.local/lib/python3.6/site-packages (0.1.0.4)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from tripod-ml) (0.14.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tripod-ml) (1.17.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from tripod-ml) (4.28.1)\n",
      "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from tripod-ml) (0.0)\n",
      "Requirement already satisfied: bpe in /root/.local/lib/python3.6/site-packages (from tripod-ml) (1.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from tripod-ml) (1.3.0+cu100)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from tripod-ml) (2.21.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->tripod-ml) (0.21.3)\n",
      "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from bpe->tripod-ml) (3.6.4)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from bpe->tripod-ml) (3.2.5)\n",
      "Requirement already satisfied: toolz in /usr/local/lib/python3.6/dist-packages (from bpe->tripod-ml) (0.10.0)\n",
      "Requirement already satisfied: mypy in /root/.local/lib/python3.6/site-packages (from bpe->tripod-ml) (0.740)\n",
      "Requirement already satisfied: hypothesis in /root/.local/lib/python3.6/site-packages (from bpe->tripod-ml) (4.43.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->tripod-ml) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->tripod-ml) (2019.9.11)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->tripod-ml) (1.24.3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->tripod-ml) (3.0.4)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->tripod-ml) (1.3.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from pytest->bpe->tripod-ml) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->bpe->tripod-ml) (41.4.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->bpe->tripod-ml) (7.2.0)\n",
      "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->bpe->tripod-ml) (0.7.1)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->bpe->tripod-ml) (1.3.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->bpe->tripod-ml) (19.3.0)\n",
      "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->bpe->tripod-ml) (1.8.0)\n",
      "Requirement already satisfied: mypy-extensions<0.5.0,>=0.4.0 in /root/.local/lib/python3.6/site-packages (from mypy->bpe->tripod-ml) (0.4.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /root/.local/lib/python3.6/site-packages (from mypy->bpe->tripod-ml) (3.7.4.1)\n",
      "Requirement already satisfied: typed-ast<1.5.0,>=1.4.0 in /root/.local/lib/python3.6/site-packages (from mypy->bpe->tripod-ml) (1.4.0)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchtext.data import Field\n",
    "from torchtext.data import TabularDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "!pip3 install tripod-ml --user\n",
    "from tripod.api import Tripod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "id": "22scBup18djc",
    "outputId": "16c3c57c-bd54-4f2f-eff5-6fbddffeed34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://github.com/adobe/tripod/raw/master/data/trained/wiki-103.zip-aa\n",
      "[========================================] 100.0%, downloading 49.00/49.00 MB ...\n",
      "https://github.com/adobe/tripod/raw/master/data/trained/wiki-103.zip-ab\n",
      "[========================================] 100.0%, downloading 49.00/49.00 MB ...\n",
      "https://github.com/adobe/tripod/raw/master/data/trained/wiki-103.zip-ac\n",
      "[========================================] 100.0%, downloading 49.00/49.00 MB ...\n",
      "https://github.com/adobe/tripod/raw/master/data/trained/wiki-103.zip-ad\n",
      "[========================================] 100.0%, downloading 23.74/23.74 MB ...\n",
      "\n",
      "Model extracted successfully."
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Choose what dataset you want to use: sick or snli\n",
    "DATASET='sick'\n",
    "\n",
    "tripod=Tripod(device=device)\n",
    "tripod.load('wiki-103')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "colab_type": "code",
    "id": "NLeRJg5_8djl",
    "outputId": "d25aa41b-b1aa-4539-de17-09adad7a4758"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-11-05 23:42:56--  http://alt.qcri.org/semeval2014/task1/data/uploads/sick_train.zip\n",
      "Resolving alt.qcri.org (alt.qcri.org)... 212.71.235.101\n",
      "Connecting to alt.qcri.org (alt.qcri.org)|212.71.235.101|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 87341 (85K) [application/zip]\n",
      "Saving to: ‘data/sick_train.zip’\n",
      "\n",
      "\r",
      "sick_train.zip        0%[                    ]       0  --.-KB/s               \r",
      "sick_train.zip      100%[===================>]  85.29K  --.-KB/s    in 0.01s   \n",
      "\n",
      "2019-11-05 23:42:56 (5.63 MB/s) - ‘data/sick_train.zip’ saved [87341/87341]\n",
      "\n",
      "--2019-11-05 23:42:58--  http://alt.qcri.org/semeval2014/task1/data/uploads/sick_test_annotated.zip\n",
      "Resolving alt.qcri.org (alt.qcri.org)... 212.71.235.101\n",
      "Connecting to alt.qcri.org (alt.qcri.org)|212.71.235.101|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 93443 (91K) [application/zip]\n",
      "Saving to: ‘data/sick_test_annotated.zip’\n",
      "\n",
      "sick_test_annotated 100%[===================>]  91.25K  --.-KB/s    in 0.01s   \n",
      "\n",
      "2019-11-05 23:42:58 (6.08 MB/s) - ‘data/sick_test_annotated.zip’ saved [93443/93443]\n",
      "\n",
      "Archive:  data/sick_train.zip\n",
      "  inflating: data/sick_train/SICK_train.txt  \n",
      "  inflating: data/sick_train/readme.txt  \n",
      "Archive:  data/sick_test_annotated.zip\n",
      "  inflating: data/sick_test_annotated/SICK_test_annotated.txt  \n",
      "  inflating: data/sick_test_annotated/readme.txt  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if not os.path.exists(\"./data\"):\n",
    "    !mkdir data\n",
    "\n",
    "if DATASET == 'snli':\n",
    "    !wget -P data \"https://nlp.stanford.edu/projects/snli/snli_1.0.zip\"\n",
    "    !unzip -d data/snli_1.0 data/snli_1.0.zip\n",
    "if DATASET == \"sick\":\n",
    "    !wget -P data \"http://alt.qcri.org/semeval2014/task1/data/uploads/sick_train.zip\"\n",
    "    !wget -P data \"http://alt.qcri.org/semeval2014/task1/data/uploads/sick_test_annotated.zip\"\n",
    "    !unzip -d data/sick_train data/sick_train.zip\n",
    "    !unzip -d data/sick_test_annotated data/sick_test_annotated.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W5m6nGeu8djt"
   },
   "outputs": [],
   "source": [
    "# Models from the Tripod paper\n",
    "class ModelA(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(900 * 2, 600)\n",
    "        self.fc2 = nn.Linear(600, 300)\n",
    "        self.fc3 = nn.Linear(300, 100)\n",
    "        self.fc4 = nn.Linear(100, 50)\n",
    "        self.fc5 = nn.Linear(50, 3)\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.fc4(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc5(x)\n",
    "        return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ll6kb-Zg8dj3"
   },
   "outputs": [],
   "source": [
    "class ModelB(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_out):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_out)\n",
    "        self.gru_A = nn.GRU(input_size=emb_out, hidden_size=200, num_layers=1, bidirectional=True)\n",
    "        self.gru_B = nn.GRU(input_size=emb_out, hidden_size=200, num_layers=1, bidirectional=True)\n",
    "        self.fc = nn.Linear(800, 3)\n",
    "    def forward(self, sentA, sentB):\n",
    "        embedded_A = self.embedding(sentA)\n",
    "        embedded_B = self.embedding(sentB)\n",
    "        output_A, hidden_A = self.gru_A(embedded_A)\n",
    "        output_B, hidden_B = self.gru_B(embedded_B)\n",
    "        hidden_A_concat = torch.cat((hidden_A[-2,:,:], hidden_A[-1,:,:]), dim=1)\n",
    "        hidden_B_concat = torch.cat((hidden_B[-2,:,:], hidden_B[-1,:,:]), dim=1)\n",
    "        hidden = torch.cat((hidden_A_concat, hidden_B_concat), dim=1)\n",
    "\n",
    "        out = self.fc(hidden)\n",
    "        return F.softmax(out, dim=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OYJVs-tv8dj_"
   },
   "outputs": [],
   "source": [
    "class ModelC(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_out):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_out)\n",
    "        self.gru_A = nn.GRU(input_size=emb_out, hidden_size=200, num_layers=1, bidirectional=True)\n",
    "        self.gru_B = nn.GRU(input_size=emb_out, hidden_size=200, num_layers=1, bidirectional=True)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(900 * 2, 600),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(600, 300),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(300, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 50),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc1 = nn.Linear(850, 3)\n",
    "    def forward(self, sentAtokens, sentBtokens, concatTripod):\n",
    "        embedded_A = self.embedding(sentAtokens)\n",
    "        embedded_B = self.embedding(sentBtokens)\n",
    "        output_A, hidden_A = self.gru_A(embedded_A)\n",
    "        output_B, hidden_B = self.gru_B(embedded_B)\n",
    "        hidden_A_concat = torch.cat((hidden_A[-2,:,:], hidden_A[-1,:,:]), dim=1)\n",
    "        hidden_B_concat = torch.cat((hidden_B[-2,:,:], hidden_B[-1,:,:]), dim=1)\n",
    "        hidden = torch.cat((hidden_A_concat, hidden_B_concat), dim=1)\n",
    "        \n",
    "        tripod_out = self.fc(concatTripod)\n",
    "        \n",
    "        out = torch.cat((hidden, tripod_out), dim=1)\n",
    "        out = self.fc1(out)\n",
    "        return F.softmax(out, dim=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_IqqowUq8dkH"
   },
   "outputs": [],
   "source": [
    "class ModelD(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_out):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_out)\n",
    "        self.gru_A = nn.GRU(input_size=emb_out + 900, hidden_size=200, num_layers=1, bidirectional=True)\n",
    "        self.gru_B = nn.GRU(input_size=emb_out + 900, hidden_size=200, num_layers=1, bidirectional=True)\n",
    "        self.fc = nn.Linear(800, 3)\n",
    "    def forward(self, sentA, sentB, sentAtripod, sentBtripod):\n",
    "        embedded_A = self.embedding(sentA)\n",
    "        embedded_B = self.embedding(sentB)\n",
    "        \n",
    "        embedded_A = torch.cat((embedded_A, sentAtripod.repeat(embedded_A.shape[0], 1).view(embedded_A.shape[0], -1, 900)), dim=2)\n",
    "        embedded_B = torch.cat((embedded_B, sentBtripod.repeat(embedded_B.shape[0], 1).view(embedded_B.shape[0], -1, 900)), dim=2)\n",
    "\n",
    "        output_A, hidden_A = self.gru_A(embedded_A)\n",
    "        output_B, hidden_B = self.gru_B(embedded_B)\n",
    "        hidden_A_concat = torch.cat((hidden_A[-2,:,:], hidden_A[-1,:,:]), dim=1)\n",
    "        hidden_B_concat = torch.cat((hidden_B[-2,:,:], hidden_B[-1,:,:]), dim=1)\n",
    "        hidden = torch.cat((hidden_A_concat, hidden_B_concat), dim=1)\n",
    "\n",
    "        out = self.fc(hidden)\n",
    "        return F.softmax(out, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RJXU3Ae28dkO"
   },
   "outputs": [],
   "source": [
    "if DATASET == 'sick':\n",
    "    TRAIN_PATH = './sick_train/SICK_train.txt'\n",
    "    TEST_PATH = './sick_test_annotated/SICK_test_annotated.txt'\n",
    "if DATASET == 'snli':\n",
    "    TRAIN_PATH = './snli_1.0/snli_1.0/snli_1.0_train.txt'\n",
    "    TEST_PATH = './snli_1.0/snli_1.0/snli_1.0_test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XEvG-8jk8dkW"
   },
   "outputs": [],
   "source": [
    "TEXT_FIELD = Field(sequential=True, tokenize=lambda x: x.split(), lower=True)\n",
    "LABEL = Field(sequential=False, use_vocab=False, lower=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mecdwYHu8dkk"
   },
   "outputs": [],
   "source": [
    "if DATASET == 'sick':\n",
    "    datafields = [(\"pair_ID\", None),\n",
    "                  (\"sentence_A\", TEXT_FIELD),\n",
    "                  (\"sentence_B\", TEXT_FIELD),\n",
    "                  (\"relatedness_score\", None),\n",
    "                  (\"entailment_judgment\", LABEL)]\n",
    "if DATASET == 'snli':\n",
    "    datafields = [(\"entailment_judgment\", LABEL),\n",
    "                 (\"sentence1_binary_parse\", None),\n",
    "                 (\"sentence2_binary_parse\", None),\n",
    "                 (\"sentence1_parse\", None),\n",
    "                 (\"sentence2_parse\", None),\n",
    "                 (\"sentence_A\", TEXT_FIELD),\n",
    "                 (\"sentence_B\", TEXT_FIELD),\n",
    "                 (\"captionID\", None),\n",
    "                 (\"pairID\", None),\n",
    "                 (\"label1\", None),\n",
    "                 (\"label2\", None),\n",
    "                 (\"label3\", None),\n",
    "                 (\"label4\", None),\n",
    "                 (\"label5\", None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bs486olN8dks"
   },
   "outputs": [],
   "source": [
    "# Load the data into memory and build the vocabulary\n",
    "train, test = TabularDataset.splits(path='./data', train=TRAIN_PATH, test=TEST_PATH, skip_header=True, format='TSV', fields=datafields, filter_pred=lambda x: x.entailment_judgment!='-') \n",
    "TEXT_FIELD.build_vocab(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "vW882A5_8dkz",
    "outputId": "ce8afcae-a61c-4092-e0fe-29c52e959e6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating tripod vectors for sentences A\n",
      "Calculating tripod vectors for sentences B\n",
      "Appending to dataset\n",
      "Calculating tripod vectors for sentences A\n",
      "Calculating tripod vectors for sentences B\n",
      "Appending to dataset\n"
     ]
    }
   ],
   "source": [
    "def append_tripod_vectors(dataset):\n",
    "    n_examples = len(dataset)\n",
    "    \n",
    "    all_sentences_A = [' '.join(x.sentence_A) for x in dataset]\n",
    "    all_sentences_B = [' '.join(x.sentence_B) for x in dataset]\n",
    "    \n",
    "    print(\"Calculating tripod vectors for sentences A\")\n",
    "    sentences_A_tripod = tripod(all_sentences_A, batch_size = 256)\n",
    "    print(\"Calculating tripod vectors for sentences B\")\n",
    "    sentences_B_tripod = tripod(all_sentences_B, batch_size = 256)\n",
    "    \n",
    "    print(\"Appending to dataset\")\n",
    "    for i in range(n_examples):\n",
    "        dataset[i].sentence_A_tripod = sentences_A_tripod[i]\n",
    "        dataset[i].sentence_B_tripod = sentences_B_tripod[i]\n",
    "    return dataset\n",
    "\n",
    "train, test = append_tripod_vectors(train), append_tripod_vectors(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mJGiH4H28dk8"
   },
   "outputs": [],
   "source": [
    "LABELS = {'contradiction': 0, 'neutral': 1, 'entailment': 2}\n",
    "def tokens_to_tensor(tokens):\n",
    "        return torch.LongTensor([TEXT_FIELD.vocab.stoi[t] for t in tokens])\n",
    "    \n",
    "def generate_batch(batch):\n",
    "    label = torch.LongTensor([LABELS[entry.entailment_judgment] for entry in batch])\n",
    "    sentence_A = [tokens_to_tensor(entry.sentence_A) for entry in batch]\n",
    "    sentence_B = [tokens_to_tensor(entry.sentence_B) for entry in batch]\n",
    "    sentence_A_tripod = [entry.sentence_A_tripod for entry in batch]\n",
    "    sentence_B_tripod = [entry.sentence_B_tripod for entry in batch]\n",
    "    \n",
    "    return sentence_A, sentence_A_tripod, sentence_B, sentence_B_tripod, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UB5yw4kU8dlC"
   },
   "outputs": [],
   "source": [
    "def train_func(dataset, model_name, model, optimizer, criterion, BATCH_SIZE):\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    data = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=generate_batch)\n",
    "    for idx, (sentsA, sents_A_tripod, sentsB, sents_B_tripod, labels) in enumerate(data):\n",
    "        optimizer.zero_grad()\n",
    "        labels = labels.to(device)\n",
    "        if model_name == 'A':\n",
    "            tripod_sentsA = torch.tensor(sents_A_tripod).to(device)\n",
    "            tripod_sentsB = torch.tensor(sents_B_tripod).to(device)\n",
    "            model_input = torch.cat((tripod_sentsA, tripod_sentsB), dim=1).to(device)\n",
    "            output = model(model_input)\n",
    "        if model_name == 'B':\n",
    "            sentsA = nn.utils.rnn.pad_sequence(sentsA, padding_value=TEXT_FIELD.vocab.stoi['<pad>']).to(device)\n",
    "            sentsB = nn.utils.rnn.pad_sequence(sentsB, padding_value=TEXT_FIELD.vocab.stoi['<pad>']).to(device)\n",
    "            output = model(sentsA, sentsB)\n",
    "        if model_name == 'C':\n",
    "            sentsA = nn.utils.rnn.pad_sequence(sentsA, padding_value=TEXT_FIELD.vocab.stoi['<pad>']).to(device)\n",
    "            sentsB = nn.utils.rnn.pad_sequence(sentsB, padding_value=TEXT_FIELD.vocab.stoi['<pad>']).to(device)\n",
    "            tripod_sentsA = torch.tensor(sents_A_tripod).to(device)\n",
    "            tripod_sentsB = torch.tensor(sents_B_tripod).to(device)\n",
    "            tripod_concat = torch.cat((tripod_sentsA, tripod_sentsB), dim=1).to(device)\n",
    "            output = model(sentsA, sentsB, tripod_concat)\n",
    "        if model_name == 'D':\n",
    "            sentsA = nn.utils.rnn.pad_sequence(sentsA, padding_value=TEXT_FIELD.vocab.stoi['<pad>']).to(device)\n",
    "            sentsB = nn.utils.rnn.pad_sequence(sentsB, padding_value=TEXT_FIELD.vocab.stoi['<pad>']).to(device)\n",
    "            tripod_sentsA = torch.tensor(sents_A_tripod).to(device)\n",
    "            tripod_sentsB = torch.tensor(sents_B_tripod).to(device)\n",
    "            output = model(sentsA, sentsB, tripod_sentsA, tripod_sentsB)\n",
    "        loss = criterion(output, labels)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_acc += (output.argmax(1) == labels).sum().item()\n",
    "    return train_loss / len(dataset), train_acc / len(dataset)\n",
    "\n",
    "def test_func(dataset, model_name, model, criterion, BATCH_SIZE):\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    data = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=generate_batch)\n",
    "    with torch.no_grad():\n",
    "        for idx, (sentsA, sents_A_tripod, sentsB, sents_B_tripod, labels) in enumerate(data):\n",
    "            labels = labels.to(device)\n",
    "            if model_name == 'A':\n",
    "                tripod_sentsA = torch.tensor(sents_A_tripod).to(device)\n",
    "                tripod_sentsB = torch.tensor(sents_B_tripod).to(device)\n",
    "                model_input = torch.cat((tripod_sentsA, tripod_sentsB), dim=1).to(device)\n",
    "                output = model(model_input)\n",
    "            if model_name == 'B':\n",
    "                sentsA = nn.utils.rnn.pad_sequence(sentsA, padding_value=TEXT_FIELD.vocab.stoi['<pad>']).to(device)\n",
    "                sentsB = nn.utils.rnn.pad_sequence(sentsB, padding_value=TEXT_FIELD.vocab.stoi['<pad>']).to(device)\n",
    "                output = model(sentsA, sentsB)\n",
    "            if model_name == 'C':\n",
    "                sentsA = nn.utils.rnn.pad_sequence(sentsA, padding_value=TEXT_FIELD.vocab.stoi['<pad>']).to(device)\n",
    "                sentsB = nn.utils.rnn.pad_sequence(sentsB, padding_value=TEXT_FIELD.vocab.stoi['<pad>']).to(device)\n",
    "                tripod_sentsA = torch.tensor(sents_A_tripod).to(device)\n",
    "                tripod_sentsB = torch.tensor(sents_B_tripod).to(device)\n",
    "                tripod_concat = torch.cat((tripod_sentsA, tripod_sentsB), dim=1).to(device)\n",
    "                output = model(sentsA, sentsB, tripod_concat)\n",
    "            if model_name == 'D':\n",
    "                sentsA = nn.utils.rnn.pad_sequence(sentsA, padding_value=TEXT_FIELD.vocab.stoi['<pad>']).to(device)\n",
    "                sentsB = nn.utils.rnn.pad_sequence(sentsB, padding_value=TEXT_FIELD.vocab.stoi['<pad>']).to(device)\n",
    "                tripod_sentsA = torch.tensor(sents_A_tripod).to(device)\n",
    "                tripod_sentsB = torch.tensor(sents_B_tripod).to(device)\n",
    "                output = model(sentsA, sentsB, tripod_sentsA, tripod_sentsB)\n",
    "\n",
    "            loss = criterion(output, labels)\n",
    "            test_loss += loss.item()\n",
    "            test_acc += (output.argmax(1) == labels).sum().item()\n",
    "    return test_loss / len(dataset), test_acc / len(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "colab_type": "code",
    "id": "0v7Rky_Z8dlK",
    "outputId": "5baee040-3aa0-4905-930c-cd16abc8cbe0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1  | time in 0 minutes, 4 seconds\n",
      "\tLoss: 0.0073(train)\t|\tAcc: 30.2%(train)\n",
      "\tLoss: 0.0070(valid)\t|\tAcc: 28.7%(valid)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-09573e2974de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMODEL_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMODEL_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0msecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-7bec921f8581>\u001b[0m in \u001b[0;36mtest_func\u001b[0;34m(dataset, model_name, model, criterion, BATCH_SIZE)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0mtripod_sentsA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msents_A_tripod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                 \u001b[0mtripod_sentsB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msents_B_tripod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentsA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentsB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtripod_sentsA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtripod_sentsB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "N_EPOCHS = 5\n",
    "min_valid_loss = float('inf')\n",
    "\n",
    "MODEL_NAME = 'D'\n",
    "VOCAB_SIZE = len(TEXT_FIELD.vocab.stoi)\n",
    "EMB_OUT_DIM = 256\n",
    "LEARNING_RATE = 0.01\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "if MODEL_NAME == 'A':\n",
    "    model = ModelA().to(device)\n",
    "elif MODEL_NAME == 'B':\n",
    "    model = ModelB(VOCAB_SIZE, EMB_OUT_DIM).to(device)\n",
    "elif MODEL_NAME == 'C':\n",
    "    model = ModelC(VOCAB_SIZE, EMB_OUT_DIM).to(device)\n",
    "elif MODEL_NAME == 'D':\n",
    "    model = ModelD(VOCAB_SIZE, EMB_OUT_DIM).to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=TEXT_FIELD.vocab.stoi['<pad>']).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    train_loss, train_acc = train_func(train, MODEL_NAME, model, optimizer, criterion, BATCH_SIZE)\n",
    "    test_loss, test_acc = test_func(test, MODEL_NAME, model, criterion, BATCH_SIZE)\n",
    "\n",
    "    secs = int(time.time() - start_time)\n",
    "    mins = secs / 60\n",
    "    secs = secs % 60\n",
    "\n",
    "    print('Epoch: %d' %(epoch + 1), \" | time in %d minutes, %d seconds\" %(mins, secs))\n",
    "    print(f'\\tLoss: {train_loss:.4f}(train)\\t|\\tAcc: {train_acc * 100:.1f}%(train)')\n",
    "    print(f'\\tLoss: {test_loss:.4f}(test)\\t|\\tAcc: {test_acc * 100:.1f}%(test)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cEp_ZqkL9nke"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "sicksnlitraintest.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
